
L21 人工智慧技術應用與規劃
本單元主題分類： 本單元涵蓋人工智慧技術應用與導入規劃相關主題，主要分類如下goodjob-nthu.conf.asia：
•	AI相關技術應用：包括 自然語言處理 (Natural Language Processing, NLP)、電腦視覺 (Computer Vision, CV)、生成式AI (Generative AI) 與 多模態AI (Multimodal AI) 等技術，針對不同的業務場景給出應用實例。
•	AI導入評估與規劃：涵蓋AI導入流程、痛點分析、目標設定與KPI設計、資源盤點、概念驗證 (Proof of Concept, PoC) 以及變革管理與風險管理等面向。考題常考驗導入步驟及策略如何對齊企業需求。
•	數據準備與模型選擇：包括 資料清理、特徵工程、模型選擇(依據問題型態選擇適用演算法) 等，是機器學習建模流程中的前置作業sas.com。
•	模型訓練與評估：闡述模型訓練流程與評估指標。常見評估指標如 準確度 (accuracy)、精確率 (precision)、召回率 (recall)、F1 分數 等developers.google.com；考題易考驗指標用途與模型過擬合/欠擬合概念。
•	AI系統集成與部署：探討如何將訓練好的AI模型整合入企業系統並部署上線，包括系統架構設計 (edge vs cloud)、MLOps (Machine Learning Operations) 等流程aws.amazon.com。考題方向會涉及部署方式、效能監控與維運策略等。
________________________________________
AI相關技術應用
概念說明與範例：
•	自然語言處理 (Natural Language Processing, NLP)： 使機器能理解與生成自然語言的技術aws.amazon.com。例如聊天機器人、文字分類、情感分析等應用。
•	電腦視覺 (Computer Vision, CV)： 讓機器自動識別與分析影像內容的技術aws.amazon.com。常見應用包含物體識別、人臉辨識、影像監控等。
•	生成式AI (Generative AI)： 可以產生新內容的AI類型，如生成圖像、文字或音樂等aws.amazon.com。例如利用深度學習生成藝術圖像 (如DALL·E)、語言模型生成文章 (如GPT)。
•	多模態AI (Multimodal AI)： 同時處理多種資料型態（文本、圖像、語音等）的AI模型ibm.com。例如接受圖片和文字輸入的模型，可根據場景圖像與說明生成相應內容。
這些技術各有特點與應用場景，考題常從應用案例或定義出題，需清晰區分。如NLP以文字為主、CV以影像為主、生成式AI著重內容創造、多模態AI則可跨媒體分析輸出。
考題方向與易混淆點：
•	考題方向： 可能會給出應用場景（例如「客戶留言意見分析」或「自動辨識產品瑕疵」），要求判斷使用哪種技術 (NLP 或 CV 等)。也可能問技術定義或演算法架構（如CNN、Transformer）。
•	易混淆： 生成式AI和其他AI技術的差別（生成式AI強調創造新內容）、單模態 vs 多模態差異、各技術主要應用領域需分清。例如情感分析用NLP而非CV；圖像標註不屬於NLP。
•	應試提醒： 在答題時明確列出技術全名與縮寫，並舉例說明，如「NLP(自然語言處理)主要用於文字分析，如情感分析、語意分類」。遇到具體應用題型，可先思考處理的資料型態，再對應技術。
複習要點：
•	自然語言處理 (NLP)： 讓機器理解、處理人類語言aws.amazon.com；應用於聊天機器人、語意分析；易混淆情感分析與關鍵字檢索。
•	電腦視覺 (CV)： 使機器自動辨識、描述影像aws.amazon.com；應用於圖像分類、人臉辨識等；易混淆攝影技術與演算法名稱(CNN等)。
•	生成式AI： 生成新內容的AI類型aws.amazon.com；應用於創作圖像、撰寫文章；易混淆與傳統AI差別 (強調生成能力)。
•	多模態AI： 處理多種數據型態的AIibm.com；可同時結合文字與影像輸入；易忽略相容性 (不同數據間如何整合)。
________________________________________
AI導入評估與規劃
概念說明與範例：
AI導入需要系統性規劃。第一步通常明確企業目標：分析業務痛點 (pain point)、確定AI應解決的問題ibm.com。接著設定績效指標(KPI)，例如提升銷售成長率、降低成本或提高效率等ctlm.com.tw。在此基礎上，設計AI導入流程，一般包括：資料收集與前處理、模型開發與PoC(概念驗證)、試點部署以及評估擴展。以客戶服務為例，企業可能先使用NLP技術分析客戶反饋，然後設定「提高回覆準確度」為目標，再透過PoC評估聊天機器人能否達到預期。AI導入也需考量資源盤點（人力、硬體）與變革管理(change management)──因導入AI常牽涉組織流程調整。
風險管理： 在規劃中不可忽視AI風險管理。AI系統可能產生資料偏見、隱私洩露、決策透明度不足等風險。現今業界推崇建立AI治理機制，例如依據ISO/IEC 42001設計風險管理系統dnv.commedium.com。考題可能考核心概念，如何評估隱私風險、何謂AI模型偏見 (bias)，或歐盟AI法案要求高風險AI系統需建立風險管理制度medium.com。
考題方向與易混淆點：
•	考題方向： 常考「AI導入流程首要步驟為何？」或「何者屬於KPI設定的步驟？」等。也可能考「PoC目的」「數據盤點重點」「AI變革管理內容」。
•	易混淆： 將目標設定與KPI混淆，或誤以為PoC就是最終產品部署。痛點分析通常是首步，幫助識別需求；KPI應與業務目標對齊。需分清風險評估與效益分析兩者。
•	應試提醒： 記住「先痛點分析→設定目標→設計流程→驗證效果」的順序。回答時用具體例子說明，如「首先進行痛點分析(identify pain points)，確定問題後再設定績效指標，如客訴解決率，以評估AI導入效果ctlm.com.tw。」考風險題型時，可簡述偏見、隱私等風險種類及對策。
複習要點：
•	AI導入流程： 步驟包括「明確目標→收集數據→PoC驗證→部署實施」；目標應量化、與KPI掛鉤ibm.comctlm.com.tw。
•	痛點分析： 初步識別企業需求與不足之處，確定AI應用方向；易忽略與最終指標之間的關聯。
•	關鍵績效指標 (KPI)：衡量AI專案成效的指標，例如「分類準確率」、「銷售增幅%」等ctlm.com.tw；需與業務目標一致。常見誤解是用不相關指標評估AI。
•	概念驗證 (PoC)：在小範圍內測試AI解決方案可行性；易誤認為PoC即最終產品，忽視其短期實驗性質。
•	風險管理： AI導入的風險包括資料偏誤、隱私、倫理等。應建立風險管理制度，重要的高風險AI需要設置持續監管(如依EU AI法案)medium.com。常見錯誤是忽略倫理/隱私評估。
________________________________________
數據準備與模型選擇
概念說明與範例：
數據準備是機器學習建模流程的前置作業sas.com。首先資料清理：處理缺失值、異常值與重複項，確保數據品質。接著特徵工程：依問題型態轉換與篩選資料，如對類別變數進行 One-Hot 編碼、對數值變數做標準化/縮放等。舉例：若要用機器學習預測客戶流失率，需將客戶基本資料與行為數據清洗後，將類別欄位轉為可輸入模型的形式。之後進行模型選擇：根據任務性質選擇演算法，分類任務常選決策樹、隨機森林、支持向量機(SVM)等；影像分析常選卷積神經網路(CNN)類深度學習模型。模型選擇同時考慮數據量、運算資源與解釋需求。
考題方向與易混淆點：
•	考題方向： 可能考察各種資料處理技術 (如「對缺失值常見處理方式？」) 和特徵工程方法(如「One-Hot編碼的目的？」)。模型選擇方面，題目可能問「何種模型適合處理線性/非線性問題」或「交叉驗證(cross-validation)目的」。
•	易混淆： 特徵工程常被忽視；例如將類別資料誤直接編碼為數值；或缺乏歸一化處理便使用以距離度量為基礎的演算法。容易忘記對模型進行驗證集划分。此外，過擬合 (overfitting) 和欠擬合常出現，但易與高/低精準度混淆。
•	應試提醒： 回答資料處理題時，可簡述數據清理、特徵縮放和處理類別變數的步驟。模型選擇題要明確依據資料型態(例如影像、文字、數值)和訓練目標(分類或回歸)來挑演算法。熟悉常見演算法名稱與適用場景，如「隨機森林適用於分類且資料量較大」等。
複習要點：
•	資料清理： 處理缺失值、異常值；如填補或刪除缺失數據；應用於確保數據品質，易錯誤刪除過多數據導致樣本不足。
•	特徵工程： 包括標準化、特徵縮放和類別編碼；例如 One-Hot 編碼將類別變數轉為二元特徵；常見錯誤是對不需縮放的變數(如樹模型)進行不必要轉換。
•	模型選擇： 根據問題型態選擇模型，分類任務可選決策樹、隨機森林等；迴歸任務可選線性回歸、SVR等；常見錯誤是不分資料特性而盲目選用模型。
•	過擬合/欠擬合： 過擬合指模型過度學習訓練數據雜訊；欠擬合則無法捕捉數據模式；考題可能問預防方法，如交叉驗證、正則化；混淆點是不理解其與資料量、模型複雜度的關係。
________________________________________
模型訓練與評估
概念說明與範例：
完成資料準備後即進入模型訓練階段。常規流程包括將資料集分為訓練集和測試集，或進行多折交叉驗證(cross-validation)以評估模型穩定度。在訓練時根據選擇的演算法優化參數，直到模型在驗證集上表現最佳。訓練結束後，使用評估指標來衡量模型性能developers.google.com。例如在二元分類問題中，準確率(Accuracy) 表示整體分類正確比例，但在類別不平衡時應注意其限制developers.google.com；可同時考慮精確率(Precision)、召回率(Recall) 及其F1 分數。迴歸問題則常用均方誤差(MSE)、R²等指標。舉例：若模型用來預測客戶購買行為，需評估在測試資料上的預測正確度，並檢查是否存在過度擬合(訓練準確率遠高於測試準確率)。
考題方向與易混淆點：
•	考題方向： 可能問常見評估指標含義（如「precision代表什麼？」）、混淆矩陣(confusion matrix)元素(真陽性TP、偽陰性FN等)、或訓練過程中交叉驗證的目的。常見題型亦涉及如何辨別過擬合與欠擬合。
•	易混淆： 容易將精確率和召回率混淆，或忘記針對不同應用選指標。例如在醫療診斷中，召回率更重要；在垃圾郵件過濾中，可能關注精確率。另過擬合常見誤解是僅歸咎於演算法，實則需看訓練資料與模型複雜度。
•	應試提醒： 答題時指出指標全名與用途，如「精確率(Precision)考慮假陽性，召回率(Recall)考慮假陰性」。對於過擬合題型，可提及使用更多資料、簡化模型、正則化或早停(early stopping)等解決方式。必要時畫簡易混淆矩陣輔助說明。
複習要點：
•	評估指標： 准確率(accuracy)、精確率(precision)、召回率(recall)、F1分數等指標developers.google.com；應用於分類問題，常見錯誤是只看準確率而忽略資料不平衡問題。
•	混淆矩陣： 包含 TP、FP、TN、FN 四種結果；常用於計算前述指標；易錯將假陰性（FN）與假陽性（FP）混淆。
•	交叉驗證： 用於評估模型在不同資料切割下的穩定性；常見錯誤是訓練時未進行驗證集/交叉驗證，導致無法判斷過擬合。
•	過擬合與欠擬合： 過擬合指模型記住訓練資料雜訊，欠擬合指模型學習不足；常見解決方法包括增大資料量、正則化、簡化模型架構等。
________________________________________
AI系統集成與部署
概念說明與範例：
訓練完成的AI模型需部署到真實環境中。系統架構設計時需決定部署平台：可部署在雲端(Cloud)或邊緣(Edge)，或兩者混合。例如企業網站後端可用雲服務建立API伺服器，讓模型提供預測服務；手機應用可能將部分AI功能整合到裝置端以降低延遲。部署過程通常使用容器化技術(如Docker)與持續整合/持續部署 (CI/CD) 管道，確保模型能快速更新與回滾。現代實踐中採用MLOps(Machine Learning Operations)來自動化整個生命週期aws.amazon.com：從模型開發、測試，到發布和基礎設施管理皆納入流程。例如，使用自動化工具定期重新訓練模型並更新服務。部署後，還需進行監控與維運：監控模型效能指標、資料漂移等，並適時重新訓練或調整。
考題方向與易混淆點：
•	考題方向： 可能問「何謂MLOps？」「模型部署後應監控哪些指標？」「邊緣部署與雲端部署的差異？」等。也可能涉及版本控制、容器化的基本概念。
•	易混淆： 模型開發與部署階段須分開思考。常見誤解是只注重開發階段而忽視運維。如認為模型上線即完工，實際上還需持續監控與更新。對MLOps概念不熟悉者容易忽略其實際意義。
•	應試提醒： 闡述部署流程時可提及MLOps：它將機器學習開發與部署自動化aws.amazon.com。例如答題可說「透過MLOps實踐，可實現模型從訓練到上線的自動化，如自動化部署至雲端與版本管理」。對於監控題型，回答需包含效能監測與資料品質檢測兩方面。
複習要點：
•	系統架構：決定採用雲端 (Cloud) 還是邊緣 (Edge) 部署；雲端靈活易擴充，邊緣低延遲。錯誤點在於不考慮資料安全與網絡延遲。
•	MLOps：整合機器學習開發 (Dev) 與部署運維 (Ops) 的實踐aws.amazon.com；包括持續集成(CI)、持續部署(CD)、持續訓練(CT)等；易忽略跨部門協作與自動化流程。
•	容器化部署：使用Docker等工具將模型及其依賴封裝，方便移植；常見錯誤是忽略版本控制或環境一致性問題。
•	監控與維運：部署後需監測模型效能與數據漂移，及時更新；常誤解為部署即完成，忽略後續監控。
 

L22 大數據處理分析與應用 核心知識
主題類別與考點分類
本單元涵蓋統計檢定 (Statistical Test)、特徵工程 (Feature Engineering)、模型選擇與應用 (Model Selection & Application)、**模型評估指標 (Evaluation Metrics)**等主題。
•	統計檢定：包括 t 檢定、F 檢定 (ANOVA) 等平均數差異檢測，以及卡方檢定等方法。測試假設（零假設與對立假設）、顯著水準 (α)、p 值、第一類/第二類錯誤為基本概念zh.wikipedia.orgwiki.mbalib.com。
•	特徵工程：從原始資料中提取、轉換並選擇有意義特徵，以提升模型表現aws.amazon.com。常見步驟包括特徵轉換(如標準化、對數轉換、One-Hot 編碼)、特徵萃取(例如 PCA 降維)、特徵選擇(如 Filter/Wrapper/Embedded 方法)等。
•	模型選擇與應用：依據預測目標與資料特性選擇模型。監督式學習分為分類(Classification)與迴歸(Regression)模型，常見演算法包括決策樹、SVM、邏輯回歸、線性回歸等；非監督式則有分群(Clustering，如 K-means)及降維(Dimensionality Reduction，如 PCA)等。
•	模型評估指標：分類模型用混淆矩陣(Confusion Matrix)及 Accuracy、Precision、Recall、F1、ROC 曲線(AUC) 等指標評估developers.google.commedium.com；迴歸模型用 MSE、MAE、決定係數(R²) 等評估，其中 R² 表示解釋變異比例zh.wikipedia.org。
統計檢定與範例
•	t 檢定 (t-test)：比較兩組樣本平均值差異是否顯著，包括單樣本 (檢驗均值與某特定值是否相符，例如檢測身高是否等於 170 公分) 與雙樣本 (檢驗兩組均值是否相等，如一年級 vs 二年級身高)zh.wikipedia.org。應注意資料分布近似常態，方差相等假設等，或使用 Welch t 檢定處理異方差。
•	F 檢定 / 單因子方差分析 (ANOVA)：檢驗三組或以上獨立樣本平均值是否有差異（例如比較一年級、二年級、三年級三組身高平均值）。當組數 >2 時應使用 ANOVA，而不是多次進行 t 檢定，以避免累積型一錯誤。
•	卡方檢定 (Chi-square test)：用於檢驗類別資料的比例或兩個分類變數的關聯性wiki.mbalib.com。例如比較性別與購買意願的相關性。卡方檢定比對理論頻率與實際頻率，無法用於連續資料的均值比較wiki.mbalib.com。
•	檢定步驟：建立零假設 (H₀) 並計算檢定統計量，求得 p 值。若 p 值小於顯著水準 α，則拒絕 H₀，認為結果具有統計顯著性。須注意第一類錯誤 (誤拒真 H₀) 及第二類錯誤 (誤未拒 H₀) 的意義。
•	範例：若要比較一年級與二年級的平均身高差異，各年級 50 人且分布近常態，可用雙樣本 t 檢定；若要比較一年、二、三年級平均身高，應用 ANOVA F 檢定；若僅檢定一年級平均身高是否等於 170 公分，則用單樣本 t 檢定zh.wikipedia.org。卡方檢定無法用於檢測平均值是否為特定數值wiki.mbalib.com。
常見錯誤與解題提醒：避免以 t 檢定比較三組以上均值（應用 F 檢定）；避免以卡方檢定檢測平均值是否等於某值（卡方僅適用類別資料）wiki.mbalib.comzh.wikipedia.org。解題時注意題幹提示：兩組均值差異用 t 檢定，多組均值差異用 ANOVA，檢定均值等於固定值用單樣本 t 檢定zh.wikipedia.org。
特徵工程
特徵工程是將原始資料轉化為有助於模型訓練的特徵集合aws.amazon.com。主要包括：
•	特徵轉換 (Transformation)：對數值特徵做標準化、正規化、對數變換等；對類別特徵做 One-Hot 編碼、標籤編碼等。
•	特徵萃取 (Extraction)：從資料中衍生新特徵，如計算統計量 (平均數、標準差)、時間特徵，或用降維方法 (PCA) 提取主成分。
•	特徵選擇 (Selection)：從現有特徵集篩選與目標相關度高的特徵，移除冗餘或噪音特徵。方法包含 Filter、Wrapper、Embedded 等。
•	特徵建構 (Construction)：基於領域知識手動創建新特徵，例如組合、交互或拆分原有特徵。
•	特徵學習 (Feature Learning)：對於非結構化資料 (如影像、文字)，常用深度學習自動學習特徵，如卷積神經網路自動抽取圖像特徵；對文本可用詞嵌入 (word embedding) 自動生成數值向量。
範例：以房價預測為例，原始特徵包括地段、面積、房間數等。特徵工程可以對面積取對數、將地址拆解為行政區和街道名、或用 PCA 對多個特徵降維；對於房屋描述的文字，可用 TF-IDF 或詞嵌入轉為數值特徵。特徵工程需結合領域知識，創造有預測力的特徵aws.amazon.com。
常見錯誤與解題提醒：不要將「預測 (Prediction)」誤認為特徵工程的一部分；預測屬於模型應用階段ipas.org.tw。對於影像或文字等非結構化資料，應採用特徵學習 (Feature Learning) 自動提取特徵，而非傳統特徵選擇ipas.org.tw。解題時注意：若題目問「何者不是特徵工程」，排除與特徵處理無關的選項（如「預測」）ipas.org.tw；對影像或文字選用特徵學習相關方法ipas.org.tw。
模型選擇與應用
根據預測目標與資料型態選擇模型：
•	分類模型 (Classification)：預測離散標籤，例如客戶類型、有/無疾病等。常用演算法：決策樹 (Decision Tree)、隨機森林、支持向量機 (SVM)、邏輯迴歸 (Logistic Regression) 等；評估指標多用 Accuracy、Precision、Recall、AUC 等。
•	迴歸模型 (Regression)：預測連續數值，例如房價、銷售量。常用演算法：線性迴歸 (Linear Regression)、多項式迴歸、決策樹回歸、支持向量回歸 (SVR) 等；評估指標用 MSE、MAE、R² 等。
•	分群模型 (Clustering)：無監督學習，用以找出資料群組結構。例如 K-means、階層聚類 (Hierarchical)、DBSCAN 等，常用於客群分群、異常偵測等。
•	降維/特徵抽取 (Dimensionality Reduction)：如主成分分析 (PCA)，用於簡化特徵空間、去除共線性，並常用於資料可視化。
範例：預測下一季銷售量為連續數值預測問題，應使用迴歸模型 (如線性迴歸)ipas.org.tw；若預測顧客是否會購買，則用分類模型；若想根據購買行為自行發現客群，可用 K-means 等分群模型；若想從產品評論文字中抽取特徵，可用詞嵌入或深度學習。
常見錯誤與解題提醒：不要將回歸問題誤用分類模型；務必確認預測目標屬於「數值 (Regression)」還是「類別 (Classification)」。例如樣題中預測產品銷售數量，答案應選迴歸模型 (線性迴歸)ipas.org.tw。若題目描述不明確（如說「分布模式」而非具體預測），需判斷是否為分群或時序分析等。過擬合和欠擬合的概念雖常出現在模型評估階段，但了解 bias-variance 也是選模型時的背景知識。
模型評估指標
•	混淆矩陣 (Confusion Matrix)：二分類常見，包含真陽性 (TP)、假陽性 (FP)、真陰性 (TN)、假陰性 (FN)。
•	準確率 (Accuracy)：所有預測正確的比例 = (TP+TN)/(TP+FP+TN+FN)。對平衡資料而言，Accuracy 可作為粗略指標developers.google.com；但在類別不平衡時不宜單獨使用。
•	精確度 (Precision)：預測為正例的結果中實際為正的比例 = TP/(TP+FP)developers.google.com。高 Precision 表示偽陽性少。在垃圾郵件分類中，它衡量標為垃圾郵件的郵件中，實際真的是垃圾郵件的比例developers.google.com。
•	召回率 (Recall, 真陽性率, TPR)：實際為正例的樣本中被正確預測為正的比例 = TP/(TP+FN)developers.google.com。高 Recall 表示偽陰性少（少漏抓正例）。例如垃圾郵件檢測的 Recall 衡量能抓到多少實際垃圾郵件developers.google.com。
•	F1 分數：Precision 與 Recall 的調和平均數developers.google.com，在兼顧兩者時使用，數值介於 0 到 1。
•	ROC 曲線 (Receiver Operating Characteristic Curve)：以假陽性率 (FPR) 為橫軸、真陽性率 (TPR) 為縱軸，顯示分類器在不同閾值下的表現medium.com。曲線越貼近左上角，表示模型性能越佳medium.com。
•	AUC (Area Under ROC Curve)：ROC 曲線下的面積，介於 0.5 到 1.0 之間。AUC 越大表示分類器整體性能越好medium.com（1.0 表示完美分類，0.5 為隨機猜測）。
•	迴歸指標：均方誤差 (MSE)、平均絕對誤差 (MAE) 衡量預測值與實際值的偏差；決定係數 (R²) 衡量模型對目標變異的解釋比例zh.wikipedia.org。R² 越接近 1，表示迴歸模型解釋力越強。
常見錯誤與解題提醒：不要在不平衡資料上只看 Accuracy，應重視 Precision、Recall 或 AUC。題目若涉及模型性能比較常用 ROC/AUC，要知道 AUC 越大越好 (曲線越接近左上角)medium.com。回歸模型的經典指標是 R²zh.wikipedia.org；如果答案選項中有 R²，通常是回歸模型評估的正確選擇。注意計算時的邊界條件，如 Precision 的分母為 0 可能導致 NaNdevelopers.google.com。總之，分類模型常用混淆矩陣相關指標，迴歸模型則用 MSE、R² 等；解題時務必弄清正例/負例定義。
總整理與比較表
•	統計檢定：檢定兩組平均差異用 t 檢定，三組以上用 F 檢定；類別資料關聯用卡方檢定zh.wikipedia.orgwiki.mbalib.com。
•	特徵工程：包含特徵轉換、萃取、選擇等步驟，預測 (Prediction) 本身不是特徵處理aws.amazon.comipas.org.tw。
•	模型類型：分類 vs 迴歸 vs 分群 vs 降維，依預測目標決定；選錯模型類型會造成預測錯誤ipas.org.tw。
•	評估指標：分類用 Accuracy、Precision、Recall、F1、ROC/AUCdevelopers.google.commedium.com；迴歸用 MSE、MAE、R²zh.wikipedia.org。
•	誤區提醒：t 檢定僅限比較兩組，超過兩組應用 ANOVA；卡方僅用於類別資料；特徵工程不包括模型「預測」階段；不平衡資料時慎用 Accuracy 考量 Precision/Recall 取捨。
•	關鍵對照表：
類別	內容/目的	方法/指標	常見誤區或提醒
統計檢定	比較群組或值之間差異	t 檢定 (兩組均值)、ANOVA/F 檢定 (多組均值)、卡方檢定 (類別資料)zh.wikipedia.orgwiki.mbalib.com
t 檢定限兩組；多組用 ANOVA；卡方僅處理類別資料
特徵工程	從資料創建或選擇有效特徵	特徵轉換(標準化、編碼)、特徵抽取(PCA)、特徵選擇(Filter/Wrapper/Embedded)aws.amazon.com
「預測」非特徵工程；文本/圖像要用特徵學習 (Feature Learning)
模型選擇	根據預測目標(類別/數值)選擇算法	分類(Decision Tree、SVM 等)、迴歸(Linear Reg.)、分群(K-means)、PCA 等	明確區分分類 vs 迴歸；錯選模型會導致錯誤預測
模型評估	衡量模型預測效果	分類: Accuracydevelopers.google.com、Precisiondevelopers.google.com、Recalldevelopers.google.com、F1developers.google.com、ROC/AUCmedium.com；迴歸: MSE、MAE、R²zh.wikipedia.org
不平衡資料慎用 Accuracy；AUC 越大越佳；需正確定義 TP/FP/FN/TN
資料來源：以上內容整理自相關機器學習與統計教材與考試範圍zh.wikipedia.orgwiki.mbalib.comaws.amazon.comdevelopers.google.com
 
L23 機器學習技術與應用
單元涵蓋主題：
•	分散式處理 (Distributed Processing)：MapReduce 等大數據並行運算架構。
•	深度學習架構 (Deep Learning Architectures)：CNN（卷積神經網路, Convolutional Neural Network）、Inception 等網路模型。
•	機器學習常見演算法：分類/回歸演算法（如決策樹、支持向量機 Support Vector Machine, 隨機森林、k-均值 (k-means) 聚類等）。
•	模型訓練問題：過度擬合 (Overfitting)、擬合不足 (Underfitting)、參數調校等。
•	模型評估指標：迴歸指標（如R² R-squared 決定係數）、分類指標（準確率 Accuracy、精確率 Precision、召回率 Recall、F1 分數、ROC 曲線下的面積 AUC 等）。
•	資料品質與偏差：資料標註品質、類別不平衡、隱私/安全與演算法公平性。
分散式處理 (MapReduce)
概念與原理： 分散式處理主要應用於大數據環境，將巨量資料拆分成小區塊平行運算。MapReduce 是一種程式設計模型，用於對大量資料進行並行且分散式處理en.wikipedia.org。其運作分為兩階段：
•	**Map 階段：**將輸入資料（通常是鍵-值對, key-value pairs）映射（轉換）為中間鍵-值對。
•	**Reduce 階段：**對 Map 階段輸出的中間結果進行合併和彙總操作。
例如，Wikipedia 定義 MapReduce 為「用於使用平行與分散式演算法處理及生成大資料集的程式模型」en.wikipedia.org；Map 階段負責過濾與分類（例如將資料按鍵分隊），Reduce 階段則執行統計或匯總（例如計算各類別總數）en.wikipedia.org。官方樣題第11題便考查此機制：題目指出 Map 階段「將一組資料映射成另一組資料」、Reduce 階段「統合與歸納資料」是正確描述ipas.org.tw。
應用場景： 大數據分析、分布式檔案系統運算（如 Hadoop、Spark 等）。常見應用例如分詞統計、日誌分析等，能將任務拆成多個 Map 任務並行處理，再集中 Reduce 彙總結果。
易懂舉例： 想像多個人同時處理一堆文件：每人(MAP)先把文件內容分成關鍵詞-次數對，然後再讓主管(REDUCE)把這些對彙總成總詞頻。
常見陷阱 / 應試提醒：
•	Map vs Reduce 誤解： Map 主要做「轉換/投影」(mapping)，不是「搜索地圖上的路徑」；Reduce 主要做「彙總匯合」，而非過濾或產生新資料。題目中若選項將 Reduce 說成「過濾不符合資料」或「生成更多資料」，即為錯誤（參見樣題11選項ipas.org.tw）。
•	注意 MapReduce 只是一種運算框架，其內部 Map 和 Reduce 函數需自行實現，例如求和或排序的具體操作。
深度學習架構 (CNN、Inception 等)
CNN (卷積神經網路)： 卷積神經網路 (Convolutional Neural Network, CNN) 是一種含有卷積運算且結構較深的前饋神經網絡，是深度學習中的代表性模型easyai.tech。CNN 專長處理影像與視覺資料，其特徵在於使用卷積層 (convolutional layers) 提取局部特徵，再經過池化層 (pooling) 減少維度。由於參數共享與稀疏連接的設計，CNN 能有效降低學習參數，同時保留空間特徵。常見應用包括圖像分類、人臉識別、物體偵測、醫學影像分析等。
Inception 網路： Google 提出的 Inception (又稱 GoogLeNet) 架構，核心在於 Inception 模組。在每個 Inception 層內，同時並行應用多種大小的卷積核（例如 1×1、3×3、5×5）及池化操作viso.ai。這使得網路「加寬」而不單純「加深」，可同時擷取多尺度特徵viso.aiviso.ai。例如，在 Inception 模組中，先以 1×1 卷積降維（減少通道數），再分別進行 3×3、5×5 卷積，最後將輸出合併viso.ai；這提高了參數效率同時增加表徵能力。官方樣題第12題即強調此差異：Inception 網路是將卷積層「加寬」而非只是「加深」ipas.org.twviso.ai。
其他知名架構：例如 ResNet（殘差網路）利用跳躍連接增加網路深度，VGG 系列透過堆疊多層固定大小卷積（3×3）加深網路。考生應注意不同架構的特點差異。
常見陷阱 / 應試提醒：
•	CNN 架構名稱混淆： 若題目選項包括 R-CNN (用於區域偵測)、ResNet、VGG 等，須分辨：Inception 著重「多尺度並行卷積」，ResNet 著重「殘差結構 + 深度」，VGG 著重「連續加深卷積層」。例如樣題12的問題描述即提示 Inception 為答案ipas.org.tw。
•	卷積層寬度 vs 深度： 不要只以「層數多少」判斷，還要看網路是否使用多種卷積核平行組合；Inception 正是平行不同大小卷積核。
模型訓練問題 (過擬合、欠擬合等)
過度擬合 (Overfitting)： 當模型過度符合訓練資料時，雖訓練誤差低，卻無法泛化到新資料ibm.comibm.com。常見於模型過於複雜或訓練次數過多。IBM 指出「模型若完全貼合訓練數據，結果便無法對訓練數據以外的任何資料做出準確預測」ibm.com。過擬合的標誌是低訓練誤差與高測試誤差ibm.com。例如，如果一名學生僅死背考古題而不理解原理，遇到變化題型就答不出，這就像模型只「背」了訓練數據而忽略一般規律。這種情況會讓模型在新數據上的表現很差。
欠擬合 (Underfitting)： 模型過於簡單或訓練不足，連訓練資料的主要趨勢都無法學到，導致訓練誤差和測試誤差皆較高ibm.com。例如只做了很少的練習，對題目都無法正確理解。過擬合與欠擬合是一對平衡：前者偏變異(variance)高、偏偏差(bias)低；後者則偏差高。
解決方法：
•	過擬合：可增加訓練資料量、簡化模型、使用正則化（如 L1/L2、Dropout）、早停法 (early stopping) 等。交叉驗證（cross-validation）也可幫助發現過擬合。
•	欠擬合：可增加模型複雜度（如更多神經元/層）、延長訓練時間或增加特徵。
考試重點：
•	判斷過/欠擬合：訓練誤差低且測試誤差高 → 過擬合；兩者皆高 → 欠擬合ibm.comibm.com。官方樣題第13題即是這類題型：訓練誤差低、測試誤差大對應「模型過度擬合」ibm.com。
•	過擬合比喻：「死背考題不懂活用」；欠擬合比喻：「基礎沒打好，題目一做就錯」。
模型評估指標 (Regression & Classification Metrics)
迴歸模型指標： 常用決定係數 (R²) 衡量迴歸模型的解釋能力en.wikipedia.org。R² 介於 0 到 1，愈接近 1 表示模型對輸出變異解釋越多。Wikipedia 說明，R² 值愈大表示迴歸模型越成功地解釋資料變異en.wikipedia.org；例如 R² = 0.8 表示模型解釋了 80% 的變異。官方樣題第14題即指出評估迴歸模型常用 R²ipas.org.twen.wikipedia.org。
(另一常見迴歸指標還有均方誤差 MSE、平均絕對誤差 MAE 等，但考題多著重 R²。)
分類模型指標： 包括準確率(Accuracy)、精確率(Precision)、召回率(Recall)、F1 分數(F1 score，精確率與召回率的調和平均) 以及ROC-AUC(Area Under ROC Curve) 等。這些指標衡量模型在正負樣本分類上的表現。
•	Accuracy： 正確預測比例。
•	Precision/Recall/F1： 常用於類別不平衡問題中（精確率指預測為正樣本中真實正樣本的比例；召回率指實際正樣本中被正確預測的比例）。
•	AUC： 衡量模型區分正負樣本的能力，數值接近1效果較好。
常見陷阱 / 應試提醒：
•	回歸 vs 分類指標： R² 只用於迴歸，不適用於分類。若題目限定「評估迴歸模型」，多半答案是 R²ipas.org.twen.wikipedia.org；而「評估分類模型」則會選 F1、Accuracy 或 AUC 等。千萬不要混淆指標用途。
•	指標定義混淆： 例如常見誤解是將 F1 分數、AUC 誤以為可用於迴歸；事實上它們都是分類演算法的性能指標。考生可根據題目是迴歸還是分類來判斷指標類型。
資料品質與偏差問題
資料品質 (Data Quality)： 包含資料的準確性、完整性、標註品質、清洗和前處理是否合格等。標註品質 (annotation quality) 尤其重要：若訓練資料標註錯誤或不一致，模型就會「學錯東西」。官方樣題第15題即指出「數據標註品質鮮少被討論，但卻直接影響模型性能」ipas.org.tw。這提醒考生注意：即使模型結構再好，也無法彌補有缺陷的標註。換言之，「Garbage In, Garbage Out」，資料有問題就別想得到好模型。
類別不平衡 (Class Imbalance)： 若訓練集中某些類別的樣本遠多於其他類別，模型訓練時可能只關注多數類，忽略少數類。這會導致模型對多數類預測較好，對少數類效果差，產生偏差。例如醫療影像中陽性病人少於陰性病人時，模型易忽視陽性。Milvus 總結指出，類別不平衡會導致模型傾向多數類，降低泛化能力milvus.io。常見解決方法包括重抽樣 (oversampling/undersampling)、加權損失函數或生成合成少數類樣本 (如 SMOTE)。
演算法偏見與公平性： 除了統計性偏差，還要考慮訓練數據是否對某些群體不公平。若數據本身含有性別、種族等偏見，模型學到的結果可能不公vocus.cc。本單元亦強調在醫療、金融等領域應防止算法歧視。
常見陷阱 / 應試提醒：
•	資料假設： 不要以為訓練資料永遠完美。官方第15題就考「標註品質如何影響模型」。遇到與資料品質相關的題目，應思考標註錯誤、缺失值、偏差等因素。
•	數據偏差迷思： 常見誤解是「只要模型足夠好，資料缺陷可以忽略」；實際上資料缺陷可能導致模型一開始就站錯位置。考題若問「數據可能存在的問題」，正答通常與標註或不平衡有關ipas.org.twmilvus.io。
常見陷阱與應試提醒
•	MapReduce 角色：一定要記住 Map 是「轉換」資料、Reduce 是「彙總」資料。若選項說 Map 做搜索或 Reduce 做過濾，多半是陷阱（樣題11 即強調正確角色ipas.org.tw）。
•	CNN 架構選擇：熟記 Inception 與其他 CNN 的差異──Inception 以並行多尺度卷積 (寬度擴張) 為特色viso.ai；ResNet 以深層殘差結構著稱；R-CNN 屬物體偵測方法，不要混用。樣題12問 Inception 的特性，可作為區別考點ipas.org.tw。
•	過/欠擬合指標：訓練誤差和測試誤差的高低組合直接指示模型狀態。題目中若提到「訓練誤差低、測試誤差高」，答案就是過擬合ibm.com；若兩者都高，則是欠擬合ibm.com。考生可透過這一組合快速排除答案。
•	指標使用情境：回答模型評估相關題目時，注意題意「迴歸還是分類」。例如樣題14指出回歸要用 R²ipas.org.twen.wikipedia.org；分類題則要考慮精確率、召回率、AUC 等。不要誤將分類指標（如 F1）當作評估迴歸模型的標準。
•	資料問題警覺：若題目詢問資料本身的問題，首選應與品質或偏差相關。像樣題15就正確指出標註品質容易被忽略但卻影響深遠ipas.org.tw。同時應思考類別不平衡或樣本偏差對模型的影響，不要誤以為資料「自然而然」就是均衡且無偏。
概念總覽對照表 (複習用)
概念 / 指標	用途與說明	常見誤解 / 陷阱
分散式處理 / MapReduce	大數據並行處理框架。Map 階段將輸入資料轉換為中間結果，Reduce 階段合併彙總en.wikipedia.orgen.wikipedia.org。
混淆 Map 與 Reduce 功能：Map 不是「地圖式搜索」，Reduce 也不是「過濾」；考試選項常誤導。
CNN (卷積神經網絡)	深度學習用於影像分析的前饋網路easyai.tech。利用卷積核提取特徵，應用於圖像分類、物體偵測等。	混淆各架構：注意 CNN 與 R-CNN / Fast R-CNN 有不同用途（前者做分類，後者做檢測）。
Inception 模組 / GoogLeNet	Google 提出的 CNN 變體。使用並行多尺寸卷積 (1×1,3×3,5×5) 來增加特徵提取面viso.ai。
易與 ResNet、VGG 混淆：Inception 著重「寬度拓展」viso.ai；ResNet 著重「深度」；VGG 著重「堆疊深卷積」。
過度擬合 (Overfitting)	模型「記憶」訓練資料中的雜訊，導致對新資料無法良好預測。訓練誤差低、測試誤差高ibm.com。
與欠擬合混淆：過擬合誤差落差大；欠擬合則訓練與測試誤差均高ibm.com。
欠擬合 (Underfitting)	模型太簡單或訓練不足，無法擬合資料的主要趨勢，訓練與測試誤差皆高ibm.com。
混淆訓練時間與模型複雜度：訓練時間夠長且模型適當，才可確認欠擬合。
R² (決定係數)	迴歸模型性能評估指標，值介於 0~1。R² 越高表示模型能解釋越多資料變異en.wikipedia.org。
僅用於迴歸模型：不要用於分類。提到迴歸必答 R²ipas.org.tw。
分類指標 (Precision/F1/AUC)	衡量分類模型效能。如精確率 (Precision)、召回率 (Recall)、F1 分數、AUC 等。	不用於迴歸：這些指標只評估分類預測，迴歸模型不適用。避免混用。
資料標註品質 (Annotation)	資料準確性的一環，高品質標註可提升模型準確度。官方提醒：標註品質直接影響模型性能ipas.org.tw。
誤認標註是理所當然：忽略標註錯誤會致命。切勿低估「髒資料」對學習的負面影響。
類別不平衡 (Class Imbalance)	當某些類別樣本量過多或過少，會導致模型偏向多數類milvus.io。可能需要重採樣或加權處理。	誤以為多類別量大的比較重要：考試提醒考慮少數類別學習不足的影響。
參考資料： 本教材結合官方考綱與樣題ipas.org.twipas.org.twibm.comen.wikipedia.org等，並引用相關教學資源說明核心概念，供考生練習與複習使用。

