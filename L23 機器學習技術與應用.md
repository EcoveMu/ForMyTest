## L23 機器學習技術與應用

**L231 機器學習基礎數學**

**L23101 機率/統計之機器學習基礎應用**

1.  **題目**：在機器學習中，貝氏定理 (Bayes' Theorem) 主要用於什麼情境？
    (A) 計算數據的平均值與變異數
    (B) 根據新的證據更新事件發生的機率 (計算後驗機率)
    (C) 進行線性迴歸模型的參數估計
    (D) 判斷兩組數據的平均數是否有顯著差異
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，貝氏定理 (Bayes' Theorem) 描述了在已知某些條件的情況下，某一事件發生的機率。在機器學習中，它常被用於根據觀測到的新證據（數據）來更新我們對某個假設或事件發生機率的信念，即計算後驗機率 (Posterior Probability)。例如，在樸素貝氏分類器中，就是利用貝氏定理來預測樣本屬於特定類別的後驗機率。
    (A) 錯誤。計算數據的平均值與變異數屬於描述性統計 (Descriptive Statistics) 的範疇，用於總結數據的基本特徵，與貝氏定理直接更新機率的功能不同。
    (C) 錯誤。進行線性迴歸模型的參數估計通常使用最小平方法 (Least Squares Method) 或最大概似估計 (Maximum Likelihood Estimation) 等方法，而非直接應用貝氏定理來估計參數（雖然貝氏線性迴歸會用到貝氏方法，但題目問的是貝氏定理的主要用途）。
    (D) 錯誤。判斷兩組數據的平均數是否有顯著差異通常使用假設檢定中的 t-檢定 (t-test) 或 ANOVA 等統計方法，與貝氏定理更新機率的核心思想不同。




2.  **題目**：最大概似估計 (Maximum Likelihood Estimation, MLE) 的核心思想是什麼？
    (A) 選擇一組參數，使得在這些參數下，觀測到目前樣本數據的機率最小
    (B) 選擇一組參數，使得在這些參數下，觀測到目前樣本數據的機率最大
    (C) 選擇一組參數，使得模型的複雜度最低
    (D) 選擇一組參數，使得模型的預測誤差最小
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，最大概似估計 (Maximum Likelihood Estimation, MLE) 是一種在給定觀測數據的情況下，估計模型參數的方法。其核心思想是：選擇一組能夠使得「已觀測到的樣本數據出現的機率（即概似函數值）」最大的參數值，作為參數的最佳估計。換句話說，我們認為最合理的參數估計，應該是那個最能解釋我們手中現有數據的參數。
    (A) 錯誤。這與MLE的核心思想相反。MLE旨在最大化觀測數據出現的機率，而非最小化。
    (C) 錯誤。選擇使得模型複雜度最低的原則通常與奧卡姆剃刀原則 (Occam's Razor) 或正規化 (Regularization) 方法相關，旨在防止過擬合，而非MLE的核心思想。MLE本身不直接考慮模型複雜度，而是專注於數據的概似程度。
    (D) 錯誤。選擇使得模型的預測誤差最小是許多機器學習模型訓練的目標，例如透過最小化損失函數（如均方誤差、交叉熵）來實現。雖然MLE的結果往往能導向預測誤差較小的模型，但其直接優化的目標是概似函數，而非預測誤差本身。




3.  **題目**：在假設檢定中，若p值 (p-value) 小於顯著水準 (significance level, α)，通常會做出何種決策？
    (A) 接受虛無假設 (Null Hypothesis)
    (B) 拒絕虛無假設，接受對立假設 (Alternative Hypothesis)
    (C) 增加樣本數重新進行檢定
    (D) p值與顯著水準無關
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，在假設檢定中，p值 (p-value) 是指在虛無假設 (Null Hypothesis, H0) 為真的前提下，觀測到目前樣本結果或更極端結果的機率。顯著水準 (significance level, α) 是一個預先設定的閾值（通常是0.05或0.01），代表我們願意承擔的犯第一型錯誤（即錯誤地拒絕一個真實的虛無假設）的最大機率。當計算出來的p值小於顯著水準α時，表示觀測到的數據與虛無假設的預期差異足夠大，這種差異不太可能是由隨機抽樣造成的。因此，我們有足夠的證據拒絕虛無假設，並接受對立假設 (Alternative Hypothesis, H1 或 Ha)。
    (A) 錯誤。接受虛無假設是在p值大於或等於顯著水準α時的決策，表示沒有足夠的證據拒絕虛無假設。
    (C) 錯誤。雖然增加樣本數可能會影響檢定結果（例如增加檢定力），但當p值小於α時，標準的決策是拒絕虛無假設，而不是立即要求增加樣本數。是否需要增加樣本數是另一個層面的考量，例如檢定力不足或結果不夠精確時。
    (D) 錯誤。p值與顯著水準密切相關，它們是做出統計決策的關鍵依據。決策規則就是比較p值和α的大小。




4.  **題目**：下列何種機率分佈常用於描述在固定時間間隔或空間區域內，某事件發生次數的機率？
    (A) 常態分佈 (Normal Distribution)
    (B) 伯努利分佈 (Bernoulli Distribution)
    (C) 二項分佈 (Binomial Distribution)
    (D) 泊松分佈 (Poisson Distribution)
    **答案**：D
    **詳解**：
    (D) 正確。根據知識文件，泊松分佈 (Poisson Distribution) 是一種離散機率分佈，用於描述在一個固定的時間間隔、空間區域、或指定的單位內，某一獨立事件發生的平均次數已知（通常用λ表示）的情況下，該事件實際發生k次的機率。例如，一小時內到達某服務台的顧客人數、一頁書中的錯字數量等，都可能服從泊松分佈。
    (A) 錯誤。常態分佈 (Normal Distribution)，也稱高斯分佈，是一種連續機率分佈，描述了許多自然現象中連續變量的分佈情況，其圖形呈鐘形。它與描述固定區間內事件發生次數的泊松分佈不同。
    (B) 錯誤。伯努利分佈 (Bernoulli Distribution) 是一種離散機率分佈，描述的是單次隨機試驗的結果，該試驗只有兩種可能的結果（例如成功/失敗，正面/反面），通常用0和1表示。它關注的是單次試驗，而非固定區間內的發生次數。
    (C) 錯誤。二項分佈 (Binomial Distribution) 是一種離散機率分佈，描述的是在n次獨立的伯努利試驗中，成功發生k次的機率，其中每次試驗成功的機率p保持不變。它關注的是固定次數試驗中的成功次數，而泊松分佈關注的是固定區間內的事件發生次數，且泊松分佈可以看作是當n很大、p很小時二項分佈的極限情況。

**L23102 線性代數之機器學習基礎應用**




5.  **題目**：在機器學習中，特徵向量 (feature vector) 通常如何表示？
    (A) 一個純量 (scalar)
    (B) 一個包含多個數值的一維陣列或向量
    (C) 一個二維的數值表格 (矩陣)
    (D) 一個高維的張量 (tensor)
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，在機器學習中，一個樣本或一個觀測對象通常由一組特徵 (features) 來描述。這些特徵的數值被組織成一個有序的列表或陣列，稱為特徵向量 (feature vector)。每個特徵向量代表數據集中的一個實例，向量中的每個元素對應一個特定的特徵值。因此，它是一個包含多個數值的一維陣列或向量。
    (A) 錯誤。一個純量 (scalar) 是一個單一的數值，它只能表示一個特徵，而特徵向量通常包含描述一個樣本的多個特徵。
    (C) 錯誤。一個二維的數值表格通常表示一個矩陣 (matrix)。在機器學習中，整個數據集（包含多個樣本的特徵向量）可以表示為一個矩陣，其中每一行（或每一列，取決於約定）是一個特徵向量。但單個樣本的特徵向量本身是一維的。
    (D) 錯誤。一個高維的張量 (tensor) 是向量和矩陣向更高維度的推廣。例如，彩色圖像可以表示為三維張量（高度 x 寬度 x 顏色通道）。雖然某些類型的數據（如圖像、影片）可以用張量表示，並且張量中的某個切片可能被視為特徵向量，但「特徵向量」本身最基礎和普遍的定義是一個一維的數值陣列。




6.  **題目**：計算兩個向量的點積 (dot product) 在機器學習中有何用途？
    (A) 判斷兩個向量是否正交 (垂直)
    (B) 計算向量的長度或大小
    (C) 作為神經網路中加權和計算的一部分
    (D) 以上皆是
    **答案**：D
    **詳解**：
    (D) 正確。向量點積在機器學習中有多種重要用途：
        (A) 判斷兩個向量是否正交：如果兩個非零向量的點積為0，則它們互相正交（垂直）。這在理解特徵之間的關係或某些演算法（如PCA中的主成分）時很有用。
        (B) 計算向量的長度或大小（範數）：一個向量與其自身的點積的平方根即為該向量的歐幾里德長度（L2範數）。即 ||v|| = sqrt(v ⋅ v)。向量長度在距離計算、正規化等操作中非常關鍵。
        (C) 作為神經網路中加權和計算的一部分：在神經網路的每個神經元中，輸入特徵向量會與權重向量進行點積運算，然後加上一個偏置項，再通過活化函數。這個點積（加權和）是神經元計算的核心步驟。
        因此，以上所有選項都是向量點積在機器學習中的正確用途。




7.  **題目**：奇異值分解 (Singular Value Decomposition, SVD) 是一種重要的矩陣分解技術，它在機器學習中的應用不包含下列何者？
    (A) 降維 (Dimensionality Reduction)，如主成分分析 (PCA) 的一種實現方式
    (B) 推薦系統中的協同過濾
    (C) 自然語言處理中的潛在語義分析 (LSA)
    (D) 直接用於訓練深度卷積神經網路的卷積層
    **答案**：D
    **詳解**：
    (D) 正確。奇異值分解 (SVD) 是一種強大的矩陣分解技術，廣泛應用於數據科學和機器學習中。然而，它並不直接用於訓練深度卷積神經網路 (CNN) 的卷積層。CNN的卷積層是透過反向傳播演算法和梯度下降來學習其卷積核（權重）的，而不是直接使用SVD的結果作為卷積核。
    (A) 錯誤，這是SVD的應用。SVD是主成分分析 (PCA) 的一種數學基礎和實現方式。透過SVD可以找到數據的主要變異方向，從而進行降維。
    (B) 錯誤，這是SVD的應用。在推薦系統中，SVD常被用於協同過濾，例如透過分解用戶-物品評分矩陣來發現潛在特徵，進而預測用戶對未評分物品的偏好。
    (C) 錯誤，這是SVD的應用。在自然語言處理中，潛在語義分析 (Latent Semantic Analysis, LSA) 或潛在語義索引 (Latent Semantic Indexing, LSI) 利用SVD來分析詞彙-文檔矩陣，以捕捉詞彙和文檔之間的潛在語義關係，用於資訊檢索和文本分析。




8.  **題目**：在線性代數中，矩陣的特徵值 (eigenvalue) 與特徵向量 (eigenvector) 描述了矩陣在特定方向上的什麼特性？
    (A) 矩陣的行數與列數
    (B) 矩陣經過線性變換後，特徵向量的方向不變，僅在長度上以特徵值為比例進行縮放
    (C) 矩陣的轉置與逆矩陣
    (D) 矩陣的行列式值
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，對於一個給定的方陣A，如果存在一個非零向量v和一個純量λ，使得Av = λv成立，那麼λ就被稱為矩陣A的一個特徵值 (eigenvalue)，而v則被稱為對應於特徵值λ的特徵向量 (eigenvector)。這個等式的幾何意義是，當矩陣A對特徵向量v進行線性變換時，其效果僅僅是將向量v在其原始方向上進行縮放，縮放的比例因子就是特徵值λ。特徵向量的方向在變換後保持不變（或者方向相反，如果特徵值為負）。
    (A) 錯誤。矩陣的行數與列數描述的是矩陣的維度或大小，與特徵值和特徵向量所描述的線性變換特性不同。
    (C) 錯誤。矩陣的轉置 (transpose) 是將矩陣的行和列互換得到的新矩陣。逆矩陣 (inverse matrix) 是指與原矩陣相乘結果為單位矩陣的矩陣（如果存在）。這些是矩陣的屬性或相關矩陣，但不是特徵值和特徵向量直接描述的特性。
    (D) 錯誤。矩陣的行列式 (determinant) 是一個與方陣相關的純量值，它可以提供關於矩陣是否可逆、線性變換對面積或體積的影響等信息，但它本身不是特徵值或特徵向量所描述的「特定方向上的特性」。特徵值的乘積等於行列式值（對於某些類型的矩陣），但這是一個間接關係。

**L23103 數值優化技術與方法**




9.  **題目**：梯度下降法 (Gradient Descent) 是一種常用的優化演算法，其更新參數的主要依據是什麼？
    (A) 損失函數的二階導數 (Hessian矩陣)
    (B) 損失函數對於模型參數的梯度 (一階導數)
    (C) 隨機選擇一個方向進行更新
    (D) 損失函數本身的值
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，梯度下降法 (Gradient Descent) 是一種迭代優化演算法，用於尋找函數的局部最小值。在機器學習中，這個函數通常是損失函數 (Loss Function)，而我們希望找到使損失函數最小化的模型參數。梯度是函數在某一點上變化最快（上升最快）的方向，其負方向則是函數下降最快的方向。因此，梯度下降法透過計算損失函數對於模型參數的梯度（即一階偏導數向量），然後沿著梯度的負方向按一定步長（學習率）更新參數，從而逐步逼近損失函數的最小值點。
    (A) 錯誤。損失函數的二階導數（Hessian矩陣）被用於更高級的優化方法，如牛頓法 (Newton's method) 或擬牛頓法 (Quasi-Newton methods)。這些方法可以利用曲率信息來加速收斂，但梯度下降法本身主要依賴一階導數（梯度）。
    (C) 錯誤。隨機選擇一個方向進行更新的方法，如隨機搜索 (Random Search)，通常效率較低，且不保證能找到最優解。梯度下降法是基於梯度的確定性方向（或其估計）進行更新的。
    (D) 錯誤。雖然損失函數本身的值用於評估當前參數的好壞，但參數更新的方向是由梯度決定的，而不是直接由損失函數的值決定的。梯度指明了如何調整參數以最大程度地減少損失。




10. **題目**：在梯度下降法中，學習率 (learning rate) 的選擇有何影響？
    (A) 學習率越大，收斂速度一定越快且結果越好
    (B) 學習率越小，收斂速度一定越慢但結果越好
    (C) 學習率過大可能導致震盪或無法收斂；學習率過小可能導致收斂速度過慢
    (D) 學習率對模型訓練沒有實質影響
    **答案**：C
    **詳解**：
    (C) 正確。根據知識文件，學習率 (learning rate) 是梯度下降法中的一個關鍵超參數，它控制了每一步參數更新的幅度（即沿著梯度負方向移動的距離）。學習率的選擇對模型的訓練過程和最終性能有顯著影響：
        -   **學習率過大**：如果學習率設置得太大，參數更新的步長可能過大，導致在損失函數的谷底附近來回震盪，甚至越過最小值點，使得損失函數不降反升，最終無法收斂到最優解。
        -   **學習率過小**：如果學習率設置得太小，參數更新的步長會非常緩慢，導致模型收斂到最優解的速度非常慢，需要更多的迭代次數，增加了訓練時間。
        因此，選擇一個合適的學習率至關重要，它需要在收斂速度和收斂穩定性之間取得平衡。
    (A) 錯誤。學習率越大，收斂速度不一定越快，如果過大反而可能導致不收斂或震盪，結果也可能更差。
    (B) 錯誤。學習率越小，收斂速度確實會變慢，但並不保證結果一定越好。過小的學習率可能導致模型陷入局部最小值，或者需要極長的訓練時間才能達到一個好的解。
    (D) 錯誤。學習率對模型訓練有非常實質的影響，是梯度下降法能否成功找到最優解的關鍵因素之一。




11. **題目**：隨機梯度下降法 (Stochastic Gradient Descent, SGD) 與批次梯度下降法 (Batch Gradient Descent) 的主要區別是什麼？
    (A) SGD 使用整個訓練集的梯度來更新參數，BGD 使用單一樣本
    (B) SGD 每次使用單一或小批量樣本的梯度來更新參數，BGD 使用整個訓練集
    (C) SGD 的計算成本通常高於 BGD
    (D) BGD 的收斂路徑通常比 SGD 更不穩定
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，梯度下降法有幾種變體，主要區別在於每次參數更新時使用的數據量：
        -   **批次梯度下降法 (Batch Gradient Descent, BGD)**：在每次參數更新時，使用整個訓練集的數據來計算損失函數的梯度。這種方法計算的梯度更準確，收斂路徑更穩定，但當訓練集非常大時，每次迭代的計算成本很高，且可能難以處理無法一次性載入記憶體的數據集。
        -   **隨機梯度下降法 (Stochastic Gradient Descent, SGD)**：在每次參數更新時，僅使用訓練集中的一個隨機選擇的樣本來計算梯度。這種方法每次迭代的計算成本非常低，更新速度快，並且其隨機性有助於跳出局部最小值。然而，由於每次只用一個樣本，梯度估計的變異較大，導致收斂路徑較為震盪。
        -   **小批量梯度下降法 (Mini-batch Gradient Descent)**：這是介於BGD和SGD之間的一種折衷方法。它在每次參數更新時，使用訓練集中的一小部分隨機樣本（一個mini-batch）來計算梯度。這種方法結合了BGD的穩定性和SGD的效率，是目前深度學習中最常用的梯度下降變體。
        題目中的SGD指的是使用單一或小批量樣本，與BGD使用整個訓練集形成對比。
    (A) 錯誤。這描述反了。BGD使用整個訓練集，SGD使用單一（或小批量）樣本。
    (C) 錯誤。SGD（尤其是單樣本SGD）每次迭代的計算成本遠低於BGD，因為它只需要處理一個樣本而不是整個訓練集。即使是Mini-batch SGD，其計算成本也通常低於BGD（除非mini-batch大小等於整個訓練集大小）。
    (D) 錯誤。由於BGD使用整個訓練集的梯度，其收斂路徑通常比SGD更平滑、更穩定。SGD由於每次使用隨機樣本估計梯度，其收斂路徑會更加震盪和不穩定。




12. **題目**：在機器學習中，損失函數 (Loss Function) 的主要作用是什麼？
    (A) 衡量模型預測的準確程度，數值越大代表模型越好
    (B) 衡量模型預測值與真實值之間的差異，優化的目標是最小化損失函數
    (C) 用於對輸入數據進行特徵提取
    (D) 決定模型架構的複雜度
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，損失函數（也稱為成本函數或目標函數）在機器學習中扮演著核心角色。它的主要作用是量化模型預測結果與實際真實值（標籤）之間的差異或「損失」。一個好的模型應該使其預測盡可能接近真實值，因此損失函數的值越小，通常表示模型的性能越好。在模型訓練過程中，優化的目標就是調整模型的參數（例如神經網路的權重），以最小化損失函數的值。
    (A) 錯誤。損失函數衡量的是模型的「錯誤」或「損失」程度，因此其數值越小代表模型越好，而非越大越好。準確度 (Accuracy) 等指標才是數值越大代表模型越好。
    (C) 錯誤。特徵提取 (Feature Extraction) 是數據預處理或模型架構的一部分（例如CNN中的卷積層），旨在從原始數據中抽取出更有代表性、更能區分不同類別的特徵。損失函數是用於評估和指導模型學習這些特徵（以及後續的分類/迴歸任務）的好壞，而不是直接進行特徵提取。
    (D) 錯誤。決定模型架構的複雜度（例如神經網路的層數、神經元數量，或決策樹的深度等）是模型設計階段的任務，通常由開發者根據問題特性、數據量和計算資源等因素來決定。損失函數本身不決定模型架構的複雜度，但模型的複雜度會影響其最小化損失函數的能力以及是否容易過擬合。

**L232 機器學習與深度學習**

**L23201 機器學習原理與技術**




13. **題目**：下列何者是監督式學習 (Supervised Learning) 的主要特點？
    (A) 訓練數據沒有標籤，模型需要自行找出數據中的結構
    (B) 訓練數據包含輸入特徵以及對應的正確輸出標籤
    (C) 模型透過與環境互動，學習最大化獎勵的策略
    (D) 主要用於數據降維與視覺化
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，監督式學習 (Supervised Learning) 是機器學習的一大類別，其核心特點是使用帶有標籤 (labeled) 的訓練數據。這意味著提供給模型的每個輸入樣本（由一組特徵描述）都配有一個已知的、正確的輸出結果或目標值（即標籤）。模型的任務是學習從輸入特徵到輸出標籤之間的映射關係，以便能夠對新的、未見過的輸入數據進行準確的預測。常見的監督式學習任務包括分類 (Classification) 和迴歸 (Regression)。
    (A) 錯誤。訓練數據沒有標籤，模型需要自行找出數據中的內在結構、模式或分組，這描述的是非監督式學習 (Unsupervised Learning) 的主要特點，例如分群 (Clustering) 或關聯規則學習 (Association Rule Learning)。
    (C) 錯誤。模型透過與環境互動，並根據收到的獎勵或懲罰來學習最佳行動策略，以最大化長期累積獎勵，這描述的是強化學習 (Reinforcement Learning) 的主要特點。
    (D) 錯誤。數據降維 (Dimensionality Reduction)，如主成分分析 (PCA)，以及數據視覺化，通常屬於非監督式學習的範疇，因為它們旨在探索數據的結構或以更簡潔的方式表示數據，而不一定需要預先定義的標籤。雖然監督式方法也可以用於特徵選擇（一種形式的降維），但「主要用於數據降維與視覺化」更符合非監督式學習的描述。




14. **題目**：當一個機器學習模型在訓練數據上表現良好，但在未見過的測試數據上表現很差時，這種現象稱為什麼？
    (A) 欠擬合 (Underfitting)
    (B) 過擬合 (Overfitting)
    (C) 偏差 (Bias)
    (D) 變異 (Variance)
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，過擬合 (Overfitting) 是指機器學習模型在訓練數據上學到了過多的細節和噪聲，導致其對訓練數據的擬合非常好（例如，訓練誤差很低），但在新的、未見過的數據（如測試數據或實際應用中的數據）上表現不佳（例如，測試誤差很高）。模型失去了泛化能力，無法很好地適應新的數據。這通常發生在模型過於複雜（相對於數據量和數據的真實複雜度而言）或者訓練時間過長的情況下。
    (A) 錯誤。欠擬合 (Underfitting) 是指模型過於簡單，無法捕捉到數據中的基本模式和規律，導致其在訓練數據上和測試數據上都表現不佳。模型沒有充分學習數據的特性。
    (C) 錯誤。偏差 (Bias) 是指模型預測值的期望與真實值之間的差異，衡量的是模型的擬合能力。高偏差通常意味著模型欠擬合，無法很好地捕捉數據的真實關係。雖然過擬合與偏差和變異有關（通常是低偏差、高變異），但題目描述的現象直接指的是過擬合。
    (D) 錯誤。變異 (Variance) 是指模型在不同訓練數據集上訓練時，其預測結果的變化程度，衡量的是模型對訓練數據變化的敏感性。高變異通常意味著模型過擬合，對訓練數據中的噪聲過於敏感。與偏差類似，雖然過擬合通常伴隨著高變異，但題目描述的現象本身被稱為過擬合。




15. **題目**：交叉驗證 (Cross-Validation) 在機器學習中的主要目的是什麼？
    (A) 增加訓練數據的數量
    (B) 更可靠地評估模型的泛化能力，並輔助模型選擇與超參數調整
    (C) 加速模型的訓練過程
    (D) 降低模型的複雜度
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，交叉驗證 (Cross-Validation) 是一種評估機器學習模型泛化能力的統計方法。它將原始數據集劃分為多個子集（或稱為「摺」，folds），然後輪流使用其中一個子集作為驗證集（用於評估模型），其餘子集作為訓練集（用於訓練模型）。這個過程重複多次，每次使用不同的子集作為驗證集。最後，將多次評估的結果（例如準確率、誤差）平均起來，得到一個更穩定、更可靠的模型性能估計。交叉驗證的主要目的包括：
        -   **更可靠地評估模型的泛化能力**：相比於單次劃分訓練集和測試集，交叉驗證可以減少因數據劃分的隨機性帶來的評估偏差，從而更準確地反映模型在未見數據上的表現。
        -   **輔助模型選擇與超參數調整**：在比較不同模型或調整模型超參數時，可以使用交叉驗證來選擇在驗證集上平均表現最好的模型或超參數組合，以避免過擬合到特定的驗證集。
    (A) 錯誤。交叉驗證本身並不增加訓練數據的總量，它只是更有效地利用現有的數據進行模型訓練和評估。數據增強 (Data Augmentation) 等技術才是用於增加訓練數據數量的方法。
    (C) 錯誤。交叉驗證通常會增加總體的計算時間，因為模型需要被訓練和評估多次（例如，k-摺交叉驗證需要訓練k次模型）。它並不能加速單個模型的訓練過程。
    (D) 錯誤。降低模型的複雜度通常是透過正規化 (Regularization)、剪枝 (Pruning，如決策樹) 或選擇更簡單的模型架構來實現的，目的是防止過擬合。交叉驗證本身是評估工具，雖然其結果可能引導我們選擇一個複雜度較低的模型（如果該模型泛化能力更好），但它不直接降低模型的複雜度。




16. **題目**：偏差-變異權衡 (Bias-Variance Tradeoff) 描述了機器學習模型中的哪種關係？
    (A) 模型的偏差越高，變異通常也越高
    (B) 模型的偏差越低，變異通常也越低
    (C) 降低模型的偏差可能會導致變異增加，反之亦然，需要在兩者間取得平衡
    (D) 偏差與變異是完全獨立的，不存在權衡關係
    **答案**：C
    **詳解**：
    (C) 正確。根據知識文件，偏差-變異權衡 (Bias-Variance Tradeoff) 是機器學習中一個核心概念，描述了模型預測誤差的兩個主要來源之間的關係：
        -   **偏差 (Bias)**：指模型預測值的期望與真實值之間的差異。高偏差意味著模型對數據的假設過於簡單，未能捕捉到數據的真實規律，導致欠擬合 (Underfitting)。
        -   **變異 (Variance)**：指模型在不同訓練數據集上訓練時，其預測結果的變化程度或不穩定性。高變異意味著模型對訓練數據中的噪聲或隨機波動過於敏感，導致過擬合 (Overfitting)。
        偏差-變異權衡指出，通常情況下，當我們試圖降低模型的偏差時（例如，使用更複雜的模型），其變異可能會增加；反之，當我們試圖降低模型的變異時（例如，使用更簡單的模型或正規化），其偏差可能會增加。因此，在模型選擇和訓練過程中，需要在偏差和變異之間找到一個平衡點，以最小化總體的預期泛化誤差。
    (A) 錯誤。高偏差（欠擬合）的模型通常對數據不敏感，因此其變異可能較低。而高變異（過擬合）的模型通常能夠很好地擬合訓練數據，偏差可能較低。
    (B) 錯誤。理想情況下我們希望偏差和變異都低，但實際中兩者往往存在權衡關係，很難同時達到最低。
    (D) 錯誤。偏差與變異並非完全獨立，它們之間存在著此消彼長的權衡關係，是影響模型泛化能力的兩個重要且相互關聯的因素。




17. **題目**：集成學習 (Ensemble Learning) 方法，如隨機森林和梯度提升樹，其核心思想是什麼？
    (A) 只使用單一且最強大的模型進行預測
    (B) 將多個弱學習器 (weak learners) 組合起來，形成一個更強大、更穩健的學習器
    (C) 專注於簡化模型的結構以提高解釋性
    (D) 主要用於無監督學習任務
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，集成學習 (Ensemble Learning) 是一種機器學習範式，其核心思想是「三個臭皮匠，勝過一個諸葛亮」。它不依賴於單一的、可能存在缺陷的模型，而是將多個相對簡單或性能較弱的學習器（稱為基學習器或弱學習器，weak learners）的預測結果以某種方式組合起來，從而創建一個整體性能更好、更穩健、泛化能力更強的強學習器 (strong learner)。常見的集成學習方法包括Bagging（如隨機森林Random Forest）、Boosting（如梯度提升樹Gradient Boosting Trees, AdaBoost）和Stacking等。
    (A) 錯誤。這與集成學習的思想相反。集成學習正是為了避免過度依賴單一模型，特別是當單一最強模型可能很難找到或容易過擬合時。
    (C) 錯誤。雖然某些集成方法（如隨機森林中的特徵重要性）可以提供一定的可解釋性，但集成學習的主要目標通常是提升預測性能和模型的穩健性，而不是簡化模型結構以提高解釋性。事實上，集成模型通常比單個基學習器更複雜，解釋性也可能更差。
    (D) 錯誤。集成學習方法主要應用於監督式學習任務（分類和迴歸），例如隨機森林和梯度提升樹都是監督式學習演算法。雖然集成思想也可以應用於非監督式學習（例如集成聚類），但其最典型和廣泛的應用是在監督式學習中。

**L23202 常見機器學習演算法**




18. **題目**：下列哪種演算法常用於解決二元分類問題，並透過一個S型函數 (Sigmoid function) 將線性輸出轉換為機率值？
    (A) 線性迴歸 (Linear Regression)
    (B) K-均值分群 (K-Means Clustering)
    (C) 羅吉斯迴歸 (Logistic Regression)
    (D) 主成分分析 (Principal Component Analysis)
    **答案**：C
    **詳解**：
    (C) 正確。根據知識文件，羅吉斯迴歸 (Logistic Regression) 是一種廣泛應用於解決二元分類問題（即預測結果只有兩個類別，例如是/否、成功/失敗）的統計學習方法。儘管其名稱中帶有「迴歸」，但它本質上是一個分類演算法。羅吉斯迴歸首先計算輸入特徵的線性組合（類似於線性迴歸），然後將這個線性輸出透過一個S型函數（Sigmoid function，也稱為Logistic function）映射到0到1之間的值。這個值可以被解釋為樣本屬於某個正類別的機率。如果機率大於某個閾值（通常是0.5），則預測為正類別，否則預測為負類別。
    (A) 錯誤。線性迴歸 (Linear Regression) 主要用於解決迴歸問題，即預測一個連續的數值輸出，而不是分類問題。它直接輸出特徵的線性組合，不使用S型函數將其轉換為機率。
    (B) 錯誤。K-均值分群 (K-Means Clustering) 是一種非監督式學習演算法，用於將數據自動分組成K個不同的群體 (clusters)，它不需要標籤數據，也不是用於二元分類或輸出機率值。
    (D) 錯誤。主成分分析 (Principal Component Analysis, PCA) 是一種非監督式學習的降維技術，用於找到數據中方差最大的方向（主成分），並將數據投影到這些方向上以減少特徵數量。它不直接用於分類或輸出機率。




19. **題目**：決策樹 (Decision Tree) 演算法在進行節點分裂時，通常會選擇哪個特徵？
    (A) 隨機選擇一個特徵
    (B) 選擇能夠使得分裂後子節點的「純度」最高（例如，資訊增益最大或基尼不純度最小）的特徵
    (C) 選擇數值範圍最大的特徵
    (D) 選擇與目標變數相關性最小的特徵
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，決策樹 (Decision Tree) 是一種監督式學習演算法，它透過一系列的決策規則（以樹狀結構表示）來進行分類或迴歸。在構建決策樹的過程中，一個關鍵步驟是如何選擇最佳的特徵來分裂當前節點，以使得分裂後的子節點盡可能「純粹」（即子節點中的樣本盡可能屬於同一類別，或迴歸值盡可能相似）。常用的分裂標準包括：
        -   **資訊增益 (Information Gain)**：基於熵 (Entropy) 的概念，選擇能夠最大程度減少分裂後子節點熵（不確定性）的特徵，即資訊增益最大的特徵。ID3演算法使用此標準。
        -   **增益率 (Gain Ratio)**：對資訊增益進行校正，以避免偏向於選擇具有較多取值的特徵。C4.5演算法使用此標準。
        -   **基尼不純度 (Gini Impurity)**：衡量從數據集中隨機選擇一個樣本，然後隨機分配一個標籤，該樣本被錯誤分類的機率。選擇能夠使得分裂後子節點基尼不純度最小（即純度最高）的特徵。CART (Classification and Regression Trees) 演算法使用此標準。
        這些標準的核心思想都是選擇一個能夠最好地區分不同類別樣本的特徵進行分裂。
    (A) 錯誤。隨機選擇特徵進行分裂是某些集成學習方法（如隨機森林中的部分隨機性）或極端隨機樹 (Extremely Randomized Trees) 的做法，但標準的決策樹演算法（如ID3, C4.5, CART）在選擇分裂特徵時是有明確的優化目標的，而不是完全隨機。
    (C) 錯誤。特徵的數值範圍大小本身並不直接決定其對分類的貢獻。一個數值範圍小但區分能力強的特徵可能遠比一個數值範圍大但區分能力弱的特徵更適合用於分裂。
    (D) 錯誤。決策樹的目標是找到與目標變數最相關、最能區分不同目標值的特徵來進行分裂，而不是選擇相關性最小的特徵。選擇相關性最小的特徵會導致分類效果很差。




20. **題目**：支持向量機 (Support Vector Machine, SVM) 在進行分類時，其主要目標是找到什麼？
    (A) 一個能夠穿過最多數據點的超平面
    (B) 一個能夠將不同類別數據點分開，並且使得兩邊間隔 (margin) 最大的超平面
    (C) 一個能夠將所有數據點都包含在內的最小圓形
    (D) 數據點在低維空間中的最佳投影
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，支持向量機 (Support Vector Machine, SVM) 是一種強大的監督式學習演算法，常用於分類和迴歸任務。在分類任務中，SVM的核心思想是找到一個能夠將不同類別的數據點分隔開來的最佳決策邊界，這個決策邊界在二維空間中是一條直線，在更高維空間中則是一個超平面 (hyperplane)。SVM的「最佳」指的是這個超平面不僅能夠正確分開不同類別的數據，而且它到最近的來自兩個不同類別的數據點（這些點被稱為支持向量，support vectors）的距離（即間隔，margin）是最大的。最大化這個間隔有助於提高模型的泛化能力，使其對新的、未見過的數據有更好的分類效果。
    (A) 錯誤。SVM的目標不是找到穿過最多數據點的超平面。事實上，決策超平面通常不會穿過任何數據點（除非是線性不可分的情況下使用軟間隔）。
    (C) 錯誤。找到一個能夠將所有數據點都包含在內的最小圓形或球體，是與支持向量數據描述 (Support Vector Data Description, SVDD) 相關的概念，主要用於異常檢測或單類別分類，而不是標準SVM分類的主要目標。
    (D) 錯誤。數據點在低維空間中的最佳投影通常與降維技術相關，例如主成分分析 (PCA)。雖然SVM可以與核技巧 (kernel trick) 結合，將數據映射到更高維的特徵空間以實現非線性分類，但其核心目標仍然是找到最大間隔的分類超平面，而不是尋找最佳投影。




21. **題目**：K-近鄰演算法 (K-Nearest Neighbors, KNN) 如何對新的數據點進行分類或預測？
    (A) 建立一個複雜的數學模型來描述數據分佈
    (B) 找出訓練集中與新數據點最接近的K個鄰居，並根據這些鄰居的標籤進行投票或平均來決定新數據點的標籤
    (C) 透過梯度下降法優化一個損失函數
    (D) 將數據轉換到一個新的特徵空間
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，K-近鄰演算法 (K-Nearest Neighbors, KNN) 是一種簡單且直觀的非參數、懶惰學習 (lazy learning) 演算法，可用於分類和迴歸任務。其核心思想是「物以類聚」。當需要對一個新的、未標記的數據點進行預測時，KNN會執行以下步驟：
        1.  計算新數據點與訓練集中所有已知數據點之間的距離（常用的距離度量包括歐幾里德距離、曼哈頓距離等）。
        2.  選取距離新數據點最近的K個訓練數據點（即K個最近鄰居）。K是一個由使用者指定的超參數。
        3.  對於分類問題，KNN會查看這K個鄰居的類別標籤，並採用「多數投票」的原則，將新數據點預測為K個鄰居中出現次數最多的那個類別。
        4.  對於迴歸問題，KNN通常會計算這K個鄰居的目標值的平均數（或加權平均數），並將其作為新數據點的預測值。
    (A) 錯誤。KNN是一種非參數方法，它不對數據分佈做任何假設，也不會建立一個明確的數學模型來描述數據分佈（如羅吉斯迴歸或SVM那樣）。它直接依賴於訓練樣本本身進行預測。
    (C) 錯誤。KNN的訓練過程非常簡單，基本上只是儲存訓練數據。它不像許多其他機器學習演算法（如神經網路、羅吉斯迴歸）那樣需要透過梯度下降法等優化演算法來最小化一個損失函數以學習模型參數。
    (D) 錯誤。KNN直接在原始特徵空間中計算距離並進行預測，它本身不涉及將數據轉換到一個新的特徵空間。某些演算法（如SVM中的核技巧或PCA）會進行特徵空間轉換，但這不是KNN的核心機制。




22. **題目**：下列哪種演算法屬於非監督式學習，常用於將數據集自動分組成若干個相似的群體 (clusters)？
    (A) 隨機森林 (Random Forest)
    (B) K-均值分群 (K-Means Clustering)
    (C) 梯度提升機 (Gradient Boosting Machine)
    (D) 樸素貝氏分類器 (Naive Bayes Classifier)
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，K-均值分群 (K-Means Clustering) 是一種經典且廣泛使用的非監督式學習演算法，其主要目的是將一個未標記的數據集劃分成K個互不相交的群體（或簇，clusters）。「非監督式」意味著算法在學習過程中不需要預先定義的類別標籤。K-Means透過迭代的方式，試圖最小化每個群體內數據點到該群體中心（質心，centroid）的平方距離之和，從而使得同一群體內的數據點盡可能相似，而不同群體之間的數據點盡可能不同。K是需要使用者預先指定的群體數量。
    (A) 錯誤。隨機森林 (Random Forest) 是一種集成學習方法，屬於監督式學習演算法，常用於分類和迴歸問題。它透過構建多個決策樹並結合它們的預測結果來提高模型的性能和穩健性。
    (C) 錯誤。梯度提升機 (Gradient Boosting Machine, GBM) 也是一種集成學習方法，屬於監督式學習演算法，常用於分類和迴歸問題。它透過迭代地訓練一系列弱學習器（通常是決策樹），每個新的學習器都試圖修正前面學習器的殘差，從而逐步提升整體模型的性能。
    (D) 錯誤。樸素貝氏分類器 (Naive Bayes Classifier) 是一種基於貝氏定理的監督式學習演算法，常用於分類問題。它假設特徵之間在給定類別的條件下是相互獨立的（樸素假設）。




23. **題目**：主成分分析 (Principal Component Analysis, PCA) 是一種常用的降維技術，其降維的依據是什麼？
    (A) 隨機選擇部分特徵
    (B) 找到數據中方差最大的方向 (主成分)，並將數據投影到這些方向上
    (C) 根據特徵與目標變數的相關性進行排序
    (D) 增加新的合成特徵
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，主成分分析 (Principal Component Analysis, PCA) 是一種廣泛應用的非監督式學習降維技術。其核心思想是將原始高維數據投影到一個新的低維子空間上，同時盡可能多地保留原始數據的變異性 (variance)。PCA透過找到數據中方差最大的方向（稱為第一主成分），然後找到與第一主成分正交且方差次大的方向（稱為第二主成分），以此類推，直到找到所需數量的互相正交的主成分。這些主成分構成了新的特徵空間，原始數據可以投影到這個由前k個主成分構成的低維空間中，從而達到降維的目的。選擇方差最大的方向是因為方差越大，通常意味著該方向上包含的資訊越多。
    (A) 錯誤。隨機選擇部分特徵是一種簡單的特徵選擇方法，但它不考慮特徵之間的相關性或數據的整體結構，通常效果不如PCA。PCA是基於數據的協方差結構來找到最佳投影方向的。
    (C) 錯誤。根據特徵與目標變數的相關性進行排序並選擇相關性高的特徵，是一種監督式的特徵選擇方法（例如，使用皮爾森相關係數或互信息）。PCA是非監督式的，它在降維過程中不考慮目標變數。
    (D) 錯誤。增加新的合成特徵通常是特徵工程 (Feature Engineering) 的一部分，目的是創造更有用的特徵，而不是降維。PCA是透過投影到一個由原始特徵線性組合而成的新特徵（主成分）空間來減少維度，而不是增加特徵。

**L23203 深度學習原理與框架**




24. **題目**：在類神經網路中，活化函數 (Activation Function) 的主要作用是什麼？
    (A) 對輸入數據進行標準化
    (B) 為神經元引入非線性，使得網路能夠學習更複雜的模式
    (C) 計算損失函數的值
    (D) 初始化網路的權重參數
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，活化函數 (Activation Function) 是類神經網路（或深度學習模型）中神經元的一個關鍵組成部分。在神經元接收到所有輸入的加權和（再加上偏置項）之後，這個結果會被傳遞給活化函數。活化函數的主要作用是引入非線性 (non-linearity) 到網路中。如果沒有非線性活化函數，多層神經網路本質上仍然是一個線性模型，其表達能力將非常有限，無法學習和表示複雜的數據模式（例如圖像識別、自然語言理解中的複雜關係）。常見的非線性活化函數包括 Sigmoid、Tanh、ReLU (Rectified Linear Unit) 及其變體等。這些函數使得神經網路能夠逼近任意複雜的非線性函數，從而處理現實世界中的複雜問題。
    (A) 錯誤。對輸入數據進行標準化 (Standardization) 或歸一化 (Normalization) 是數據預處理的一個步驟，目的是將數據調整到一個合適的範圍（例如均值為0，標準差為1），以幫助模型訓練的穩定性和收斂速度。這通常在數據進入網路之前完成，而不是活化函數的主要作用。
    (C) 錯誤。計算損失函數 (Loss Function) 的值是在模型進行預測之後，用於衡量預測結果與真實標籤之間的差異。損失函數指導模型的優化過程，但它不是活化函數本身的功能。
    (D) 錯誤。初始化網路的權重參數是模型訓練開始前的一個重要步驟，目的是為權重賦予初始值。權重初始化的好壞會影響模型的訓練效果，但這與活化函數的作用不同。活化函數是在前向傳播過程中對神經元的輸出進行非線性變換。




25. **題目**：反向傳播演算法 (Backpropagation) 在深度學習模型訓練中的核心功能是什麼？
    (A) 對輸入圖像進行特徵提取
    (B) 高效地計算損失函數對於網路中所有權重參數的梯度，以便進行權重更新
    (C) 隨機初始化神經網路的權重
    (D) 決定神經網路的層數與每層的神經元數量
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，反向傳播演算法 (Backpropagation) 是訓練多層神經網路（深度學習模型）的核心演算法。在模型進行一次前向傳播 (forward pass) 並計算出預測值與損失函數值之後，反向傳播演算法會從輸出層開始，逐層向後計算損失函數對於網路中每一個權重 (weight) 和偏置 (bias) 參數的梯度（即偏導數）。這些梯度指明了每個參數應該如何調整才能使損失函數減小。一旦計算出所有梯度，就可以使用梯度下降法（或其變體，如SGD, Adam等）來更新網路的參數。反向傳播的關鍵在於它利用了微積分中的鏈式法則 (chain rule)，能夠高效地計算這些梯度，即使對於非常深和複雜的網路也是如此。
    (A) 錯誤。對輸入圖像進行特徵提取是卷積神經網路 (CNN) 等模型在前向傳播過程中的一部分功能，例如卷積層和池化層會自動學習和提取圖像特徵。反向傳播是發生在特徵提取和預測之後，用於計算梯度以更新模型參數的過程。
    (C) 錯誤。隨機初始化神經網路的權重是在模型訓練開始之前進行的一個重要步驟，目的是打破對稱性並幫助模型開始學習。反向傳播是在權重初始化之後，用於在訓練過程中調整這些權重。
    (D) 錯誤。決定神經網路的層數與每層的神經元數量是模型架構設計的一部分，通常由人工設計或透過神經架構搜索 (Neural Architecture Search, NAS) 等技術來確定。反向傳播演算法本身不決定網路的架構，而是在給定架構下訓練模型參數。




26. **題目**：卷積神經網路 (Convolutional Neural Network, CNN) 特別擅長處理哪種類型的數據？其核心組件通常包含哪些層？
    (A) 時間序列數據；循環層、注意力層
    (B) 表格數據；全連接層、決策樹層
    (C) 圖像或網格狀數據；卷積層、池化層、全連接層
    (D) 文字數據；嵌入層、LSTM層
    **答案**：C
    **詳解**：
    (C) 正確。根據知識文件，卷積神經網路 (Convolutional Neural Network, CNN 或 ConvNet) 是一種特殊設計的深度學習模型，因其在處理具有網格狀拓撲結構的數據方面表現出色而聞名，其中最典型的應用就是圖像處理和電腦視覺任務。CNN的核心思想是利用卷積運算來自動學習和提取數據中的局部空間層次特徵。其核心組件通常包括：
        -   **卷積層 (Convolutional Layer)**：透過可學習的濾波器（卷積核）對輸入數據進行卷積操作，以提取局部特徵，如邊緣、角點、紋理等。
        -   **池化層 (Pooling Layer)**：通常位於卷積層之後，用於降低特徵圖的空間維度（下採樣），減少計算量，並增強模型的平移不變性。常見的池化操作有最大池化 (Max Pooling) 和平均池化 (Average Pooling)。
        -   **全連接層 (Fully Connected Layer)**：在經過多個卷積層和池化層提取特徵後，通常會將特徵圖展平並連接到一個或多個全連接層，用於進行最終的分類或迴歸預測（類似於傳統的多層感知器）。
    (A) 錯誤。時間序列數據（如語音、股票價格）通常更適合使用循環神經網路 (RNN) 或其變體（如LSTM, GRU）以及注意力機制來處理，因為這些模型能夠捕捉序列中的時間依賴性。雖然CNN有時也用於時間序列（例如一維CNN），但其最擅長的領域是圖像等網格數據。
    (B) 錯誤。表格數據（結構化數據）通常使用傳統的機器學習演算法（如決策樹、隨機森林、梯度提升樹、支持向量機）或簡單的全連接神經網路（多層感知器）來處理。決策樹層不是標準CNN的組件。
    (D) 錯誤。文字數據（自然語言處理任務）傳統上常使用RNN、LSTM、GRU等模型，近年來Transformer模型（基於自注意力機制）取得了巨大成功。嵌入層 (Embedding Layer) 用於將文字轉換為向量表示，是處理文字數據的常見初始步驟，但CNN本身的核心組件不直接包含LSTM層。




27. **題目**：循環神經網路 (Recurrent Neural Network, RNN) 為何適合處理序列數據（如文字、語音）？
    (A) 因為其網路結構中不包含任何循環連接
    (B) 因為其隱藏層的狀態可以在不同時間步之間傳遞，從而捕捉序列中的時間依賴性
    (C) 因為它只能處理固定長度的輸入序列
    (D) 因為它不需要進行反向傳播訓練
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，循環神經網路 (Recurrent Neural Network, RNN) 的核心特點是其網路結構中包含循環連接（或稱為反饋迴路）。這使得網路的隱藏層狀態不僅依賴於當前時間步的輸入，還依賴於前一個時間步的隱藏層狀態。這種「記憶」機制允許信息在序列的不同時間步之間傳遞和保持，從而使RNN能夠有效地捕捉和學習序列數據（如文字、語音、時間序列數據等）中的時間依賴關係和上下文信息。例如，在處理一個句子時，RNN可以利用前面詞語的信息來理解當前詞語的含義。
    (A) 錯誤。這與RNN的定義相反。RNN的關鍵就在於其結構中存在循環連接，使得信息可以在時間步之間流動。
    (C) 錯誤。雖然傳統的簡單RNN在處理非常長的序列時可能會遇到梯度消失或梯度爆炸的問題，並且在實際應用中通常需要將序列截斷或填充到固定長度進行批次處理，但RNN的設計理念是能夠處理可變長度的序列。更高級的RNN變體，如長短期記憶網路 (LSTM) 和門控循環單元 (GRU)，被設計用來更好地處理長序列依賴問題。
    (D) 錯誤。RNN（包括其變體LSTM、GRU等）通常也是透過反向傳播演算法進行訓練的，不過是其適用於序列數據的變體，稱為隨時間反向傳播 (Backpropagation Through Time, BPTT)。BPTT將循環網路在時間上展開成一個深層的前饋網路，然後應用標準的反向傳播來計算梯度並更新權重。




28. **題目**：Transformer 模型近年來在自然語言處理領域取得了巨大成功，其核心機制是什麼？
    (A) 卷積運算 (Convolution)
    (B) 循環連接 (Recurrent Connection)
    (C) 注意力機制 (Attention Mechanism)，特別是自注意力機制 (Self-Attention)
    (D) K-均值分群 (K-Means Clustering)
    **答案**：C
    **詳解**：
    (C) 正確。根據知識文件，Transformer 模型（由 Vaswani 等人在論文 "Attention Is All You Need" 中提出）已經成為自然語言處理 (NLP) 領域的革命性架構，並在機器翻譯、文本生成、問答系統等眾多任務上取得了最先進的成果。其核心創新和成功的關鍵在於完全拋棄了傳統的循環連接 (RNN) 和卷積運算 (CNN) 作為主要的序列處理單元，而是完全依賴於注意力機制 (Attention Mechanism)，特別是其中的自注意力機制 (Self-Attention Mechanism)。自注意力機制允許模型在處理序列中的每個元素（例如一個詞）時，能夠同時關注到序列中所有其他元素，並根據它們之間的相關性來計算該元素的表示，從而有效地捕捉長距離依賴關係，並且能夠並行處理序列中的所有元素，大大提高了訓練效率。
    (A) 錯誤。雖然卷積運算 (Convolution) 在某些NLP模型（如文本CNN）中被用於提取局部特徵，但Transformer模型的核心並不是卷積運算。Transformer的設計初衷之一就是擺脫對卷積和循環的依賴。
    (B) 錯誤。循環連接 (Recurrent Connection) 是RNN及其變體（如LSTM, GRU）的核心特徵，用於按順序處理序列數據並捕捉時間依賴性。Transformer模型的一個主要突破就是不再使用循環連接，從而克服了RNN在處理長序列時的梯度消失/爆炸問題以及難以並行計算的缺點。
    (D) 錯誤。K-均值分群 (K-Means Clustering) 是一種非監督式學習演算法，用於將數據自動分組，與Transformer這種用於序列建模的監督式（或自監督式）深度學習架構的核心機制無關。




29. **題目**：TensorFlow 和 PyTorch 是目前主流的深度學習框架，它們為開發者提供了哪些便利？
    (A) 自動撰寫論文的功能
    (B) 提供自動微分、GPU加速、預定義的網路層與模型、以及模型部署等功能，簡化深度學習模型的開發與訓練
    (C) 內建完整的數據標註工具
    (D) 只能用於學術研究，不能用於商業應用
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，TensorFlow (由Google開發) 和 PyTorch (由Facebook AI Research開發) 是當今最流行和廣泛使用的開源深度學習框架。它們極大地簡化了深度學習模型的設計、訓練和部署過程，為開發者和研究人員提供了以下關鍵便利：
        -   **自動微分 (Automatic Differentiation)**：能夠自動計算複雜函數（如損失函數對於模型參數）的梯度，這是反向傳播演算法的核心，使得開發者無需手動推導和實現梯度計算。
        -   **GPU/TPU加速**：內建對圖形處理單元 (GPU) 和張量處理單元 (TPU) 等硬體加速器的支持，能夠顯著加速大規模深度學習模型的訓練和推斷過程。
        -   **預定義的網路層與模型**：提供了豐富的預先實現的標準神經網路層（如卷積層、循環層、全連接層、活化函數、池化層等）和常用的模型架構（如ResNet, VGG, Transformer等），開發者可以直接調用和組合，快速搭建模型。
        -   **靈活的計算圖**：TensorFlow（尤其是早期版本）使用靜態計算圖，而PyTorch使用動態計算圖，兩者都提供了構建和執行複雜計算流程的機制。
        -   **模型部署工具與生態系統**：提供了將訓練好的模型部署到各種平台（如伺服器、移動設備、嵌入式系統）的工具和庫（如TensorFlow Serving, TensorFlow Lite, TorchServe等），並擁有龐大的社區和豐富的生態資源。
    (A) 錯誤。深度學習框架本身不提供自動撰寫論文的功能。雖然AI在文本生成方面取得了進展，但這不是TensorFlow或PyTorch的核心功能。
    (C) 錯誤。雖然有一些第三方工具或庫可以與這些框架集成用於數據標註，但TensorFlow和PyTorch本身並不內建完整的數據標註工具。數據標註通常是模型開發前的一個獨立步驟。
    (D) 錯誤。TensorFlow和PyTorch不僅廣泛用於學術研究，也被大量應用於工業界和商業產品中，用於開發各種AI驅動的應用和服務。它們都是開源的，允許商業使用。

**L233 機器學習建模與參數調校**

**L23301 數據準備與特徵工程**




30. **題目**：在機器學習中，特徵工程 (Feature Engineering) 為何重要？
    (A) 它通常是模型訓練中最耗時但最不重要的環節
    (B) 透過創建更能反映數據內在規律的特徵，可以顯著提升模型的性能
    (C) 好的特徵工程可以完全取代模型選擇的過程
    (D) 特徵工程僅適用於非監督學習
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，特徵工程 (Feature Engineering) 是指利用領域知識和數據分析技能，從原始數據中提取、轉換或創建新的特徵，以供機器學習模型使用的過程。它是機器學習流程中至關重要的一環，因為模型的性能上限很大程度上取決於輸入特徵的質量。好的特徵能夠更直接、更有效地揭示數據中與預測目標相關的內在規律和模式，從而使得即使是簡單的模型也能取得良好的性能。所謂「數據和特徵決定了機器學習的上限，而模型和演算法只是在逼近這個上限」。
    (A) 錯誤。特徵工程雖然可能非常耗時，但它絕不是最不重要的環節，反而往往是對模型最終性能影響最大的環節之一。有經驗的數據科學家通常會花費大量時間在特徵工程上。
    (C) 錯誤。雖然好的特徵工程可以極大地提升模型性能，甚至使得簡單模型也能表現優異，但它不能完全取代模型選擇的過程。不同的模型適用於不同類型的數據和問題，即使有好的特徵，選擇合適的模型仍然是必要的。特徵工程和模型選擇是相輔相成的。
    (D) 錯誤。特徵工程不僅適用於非監督學習（例如，為分群演算法創建更好的特徵），也同樣重要甚至更常應用於監督式學習（例如，為分類或迴歸模型創建預測能力更強的特徵）。無論是哪種類型的學習任務，好的特徵都是提升模型性能的關鍵。




31. **題目**：處理類別型特徵 (Categorical Features) 時，獨熱編碼 (One-Hot Encoding) 的主要作用是什麼？
    (A) 將類別特徵轉換為單一的數值，保留其大小順序關係
    (B) 將具有N個可能類別的特徵轉換為N個二元特徵，避免引入不存在的順序關係
    (C) 降低特徵的維度
    (D) 填充缺失值
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，類別型特徵 (Categorical Features) 是指其值來自一個有限的、離散的集合，例如「顏色」（紅、綠、藍）或「城市」（台北、台中、高雄）。許多機器學習演算法無法直接處理這些非數值的類別標籤。獨熱編碼 (One-Hot Encoding) 是一種常用的將類別型特徵轉換為數值型特徵的方法。對於一個具有N個不同可能類別的原始特徵，獨熱編碼會創建N個新的二元（0或1）特徵。對於每個樣本，在其原始類別對應的新特徵上取值為1，而在其他N-1個新特徵上取值為0。這樣做的好處是，它將類別型數據轉換為演算法可以處理的數值格式，並且避免了直接將類別賦予數值（如紅=1, 綠=2, 藍=3）可能引入的不存在的順序關係（例如，藍色並不一定「大於」綠色）。
    (A) 錯誤。將類別特徵轉換為單一的數值並保留其大小順序關係，描述的是序數編碼 (Ordinal Encoding) 或標籤編碼 (Label Encoding) 的一種情況，適用於本身具有順序性的類別特徵（例如「學歷」：高中、大學、碩士）。對於沒有內在順序的名目型特徵 (Nominal Features)，使用這種編碼會引入誤導性的順序信息。獨熱編碼正是為了解決這個問題。
    (C) 錯誤。獨熱編碼通常會增加特徵的維度，而不是降低。如果一個類別特徵有N個可能的類別，獨熱編碼後會產生N個新的二元特徵。當N很大時，這可能導致維度災難 (curse of dimensionality)。降維是使用PCA等技術來減少特徵數量。
    (D) 錯誤。填充缺失值 (Missing Values) 是數據預處理中處理數據不完整性的一個步驟，例如使用平均數、中位數填充，或使用模型預測填充。獨熱編碼是用於轉換已有的類別型特徵的表示方式，而不是處理缺失值。




32. **題目**：當訓練數據集中不同類別的樣本數量差異巨大時（例如，欺詐檢測中欺詐樣本遠少於正常樣本），這種情況稱為什麼？應如何處理？
    (A) 過擬合；增加模型複雜度
    (B) 數據稀疏；使用降維技術
    (C) 數據不平衡 (Imbalanced Data)；可採用過採樣、欠採樣、代價敏感學習等方法
    (D) 特徵共線性；移除相關特徵
    **答案**：C
    **詳解**：
    (C) 正確。根據知識文件，當訓練數據集中不同類別的樣本數量差異巨大時，這種情況被稱為數據不平衡 (Imbalanced Data) 或類別不平衡 (Class Imbalance)。例如，在金融欺詐檢測中，欺詐交易的樣本數量通常遠遠少於正常交易的樣本數量；在醫療診斷中，患有罕見疾病的病患樣本也遠少於健康個體的樣本。數據不平衡會對許多標準的機器學習演算法產生負面影響，因為這些演算法通常假設類別分佈是相對均衡的，它們可能會過度關注多數類別而忽略少數類別，導致對少數類別的預測性能很差。處理數據不平衡問題的常見方法包括：
        -   **過採樣 (Oversampling)**：增加少數類別的樣本數量，例如隨機複製少數類樣本，或使用SMOTE (Synthetic Minority Over-sampling Technique) 等方法生成新的合成少數類樣本。
        -   **欠採樣 (Undersampling)**：減少多數類別的樣本數量，例如隨機移除部分多數類樣本，或使用一些更智能的欠採樣方法。
        -   **代價敏感學習 (Cost-Sensitive Learning)**：在模型的損失函數中為不同類別的錯分類賦予不同的代價（例如，將錯分類少數類別的代價設得更高），使得模型更關注少數類別的正確分類。
        -   **集成方法**：使用專門設計用於處理不平衡數據的集成學習方法，如EasyEnsemble, BalanceCascade等。
        -   **選擇合適的評估指標**：避免僅使用準確率 (Accuracy) 作為評估指標，因為在高不平衡情況下它可能具有誤導性。應考慮使用如精確率 (Precision)、召回率 (Recall)、F1分數 (F1-score)、AUC-ROC、AUC-PR等對不平衡更敏感的指標。
    (A) 錯誤。過擬合 (Overfitting) 是指模型在訓練集上表現好但在測試集上表現差的現象。雖然數據不平衡可能間接導致模型對多數類的過擬合，但問題本身描述的是數據不平衡。增加模型複雜度通常會加劇過擬合，而不是解決數據不平衡的方法。
    (B) 錯誤。數據稀疏 (Data Sparsity) 通常指數據集中大部分特徵值為零或缺失的情況，常見於高維數據（如文本數據的詞袋表示）。雖然數據稀疏和數據不平衡都可能給模型訓練帶來挑戰，但它們是不同的問題。使用降維技術是處理數據稀疏或高維數據的一種方法，但不直接解決類別不平衡。
    (D) 錯誤。特徵共線性 (Multicollinearity) 是指模型中的自變量（特徵）之間存在高度相關關係。這會影響迴歸模型參數估計的穩定性和解釋性。移除相關特徵是處理共線性的一種方法，但與數據不平衡問題無關。




33. **題目**：特徵縮放 (Feature Scaling)，例如標準化 (Standardization) 或歸一化 (Normalization)，在某些機器學習演算法中為何是必要的？
    (A) 為了增加特徵的數量
    (B) 確保所有特徵都在相同的數值範圍內，避免某些特徵因數值較大而主導模型的學習過程，有助於梯度下降等演算法的收斂
    (C) 為了將數值特徵轉換為類別特徵
    (D) 特徵縮放只會降低模型性能
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，特徵縮放 (Feature Scaling) 是數據預處理中一個非常重要的步驟，尤其對於那些依賴於特徵數值大小或距離計算的機器學習演算法而言。常見的特徵縮放方法包括：
        -   **標準化 (Standardization)**：將特徵數據轉換為均值為0，標準差為1的分佈（也稱為Z-score normalization）。計算公式為：(x - μ) / σ，其中μ是特徵的均值，σ是特徵的標準差。
        -   **歸一化 (Normalization)**：通常指將特徵數據縮放到一個固定的範圍，例如[0, 1]或[-1, 1]。最常見的歸一化方法是最小-最大歸一化 (Min-Max Scaling)，計算公式為：(x - min) / (max - min)。
        特徵縮放的主要原因和好處包括：
        1.  **避免數值較大的特徵主導模型學習**：如果不同特徵的數值範圍差異很大（例如，一個特徵的範圍是0-1，另一個是0-10000），那麼在使用梯度下降等優化演算法時，數值較大的特徵可能會在損失函數的計算和梯度更新中佔據主導地位，使得模型對這些特徵更敏感，而忽略了數值較小的特徵。特徵縮放可以將所有特徵置於可比較的尺度上。
        2.  **有助於梯度下降等演算法的收斂**：當特徵尺度不一時，損失函數的等高線圖可能會呈現扁長的橢圓形，導致梯度下降的收斂路徑曲折且緩慢。特徵縮放可以使等高線圖更接近圓形，從而加速梯度下降的收斂速度並提高其穩定性。
        3.  **適用於基於距離的演算法**：像K-近鄰 (KNN)、支持向量機 (SVM，尤其是使用RBF等核函數時)、K-均值分群 (K-Means) 等依賴於計算數據點之間距離的演算法，如果特徵尺度不一，數值範圍大的特徵會在距離計算中佔據主導，影響演算法的性能。特徵縮放可以確保所有特徵對距離的貢獻是公平的。
    (A) 錯誤。特徵縮放是改變現有特徵的數值範圍，而不是增加特徵的數量。增加特徵數量通常是透過特徵創建 (Feature Creation) 或特徵選擇的逆過程來實現的。
    (C) 錯誤。將數值特徵轉換為類別特徵是離散化 (Discretization) 或分箱 (Binning) 的過程，例如將年齡（數值）轉換為年齡段（類別）。特徵縮放處理的是數值特徵的尺度，而不改變其類型。
    (D) 錯誤。對於許多演算法而言，適當的特徵縮放不僅不會降低模型性能，反而通常是提升模型性能和訓練效率的關鍵步驟。當然，對於某些不受特徵尺度影響的演算法（如決策樹、隨機森林等基於樹的模型），特徵縮放可能不是必需的，但也不會顯著降低性能。




34. **題目**：下列何者不是常見的處理數據中缺失值 (Missing Values) 的方法？
    (A) 刪除包含缺失值的樣本或特徵
    (B) 使用平均數、中位數或眾數填充缺失值
    (C) 使用機器學習模型預測並填充缺失值
    (D) 將所有缺失值都視為一個新的獨立類別，而不進行任何填充
    **答案**：D (雖然有時會這樣處理，但通常不是首選或普適方法，且題目問「不是常見的」)
    **詳解**：
    (D) 正確。雖然將缺失值視為一個新的獨立類別（例如，對於一個類別型特徵，如果原來有A, B兩類，可以將缺失值視為第三類C）在某些特定情況下可能是一種處理方式，尤其是在缺失本身可能帶有某種信息時（Missing Not At Random, MNAR），但它並不像其他選項那樣被廣泛認為是「常見的」普適性處理缺失值的方法。更重要的是，題目問的是「不是常見的」方法，而其他三個選項都是非常標準和常見的處理策略。
        -   將所有缺失值都視為一個新的獨立類別，而不進行任何填充：這種方法對於數值型特徵通常不適用（除非先將數值特徵離散化）。對於類別型特徵，雖然可行，但如果缺失值數量很少，可能會產生一個樣本量極小的新類別，對模型學習不利。如果缺失值是隨機發生的（Missing Completely At Random, MCAR 或 Missing At Random, MAR），將其視為一個獨立類別可能引入偏差。

    以下是常見的處理缺失值的方法：
    (A) 錯誤，這是常見方法。刪除包含缺失值的樣本（行刪除）或特徵（列刪除）是一種簡單直接的方法。如果某個樣本的缺失值過多，或者某個特徵的缺失比例過高且該特徵不重要，可以考慮刪除。但這種方法可能會導致有價值信息的損失，尤其是在數據量較少的情況下。
    (B) 錯誤，這是常見方法。對於數值型特徵，可以使用該特徵的平均數 (mean)、中位數 (median) 或眾數 (mode) 來填充缺失值。中位數對異常值更穩健。對於類別型特徵，可以使用眾數來填充。
    (C) 錯誤，這是常見方法。可以使用機器學習模型（如K-近鄰、迴歸模型、決策樹等）來預測並填充缺失值。例如，可以將帶有缺失值的特徵作為目標變數，使用其他特徵作為預測變數來訓練一個模型，然後用模型的預測結果填充缺失值。這種方法通常比簡單的均值/中位數填充更準確，但計算成本也更高。




**L23302 模型選擇與架構設計**

35. **題目**：在選擇機器學習模型時，應主要考慮哪些因素？
    (A) 僅考慮模型的複雜度和新穎性
    (B) 問題的類型（分類、迴歸、分群等）、數據的特性（大小、維度、類型）、計算資源、模型的可解釋性需求等
    (C) 選擇訓練時間最短的模型
    (D) 選擇程式碼最少的模型
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，選擇合適的機器學習模型是一個綜合考量的過程，沒有一體適用的最佳模型（「沒有免費的午餐」定理 No Free Lunch Theorem）。主要應考慮的因素包括：
        -   **問題的類型**：是分類問題（預測離散類別）、迴歸問題（預測連續數值）、分群問題（無監督地將數據分組）、降維問題，還是其他類型的問題？不同類型的問題有其對應的適用演算法。
        -   **數據的特性**：
            -   **數據大小（樣本量）**：樣本量的大小會影響模型的選擇。小數據集可能更適合簡單模型以避免過擬合，而大數據集則可以支持更複雜的模型。
            -   **數據維度（特徵數量）**：高維數據可能需要降維處理或使用對高維數據不敏感的模型。
            -   **數據類型**：數據是數值型、類別型、文本、圖像、時間序列等？不同類型的數據有其專門的處理方法和模型。
            -   **數據質量**：數據中是否存在缺失值、異常值、噪聲等？這些都會影響模型的選擇和預處理策略。
            -   **數據的線性可分性**：如果數據是線性可分的，簡單的線性模型可能就足夠了；如果數據具有複雜的非線性結構，則可能需要非線性模型（如核SVM、神經網路）。
        -   **計算資源**：可用的CPU、GPU、記憶體等計算資源會限制模型的複雜度和訓練時間。某些複雜模型（如大型深度學習模型）需要大量的計算資源。
        -   **模型的可解釋性需求**：在某些應用場景（如金融風控、醫療診斷），模型的可解釋性非常重要，需要能夠理解模型是如何做出決策的。在這種情況下，可能會選擇本身具有較好可解釋性的模型（如決策樹、線性迴歸），或者使用XAI技術來解釋複雜模型。
        -   **訓練時間與預測時間要求**：某些應用對模型的訓練速度或預測速度有嚴格要求。
        -   **模型的性能指標**：根據具體問題，選擇合適的評估指標（如準確率、精確率、召回率、F1分數、MSE等）來衡量和比較不同模型的性能。
    (A) 錯誤。僅僅追求模型的複雜度和新穎性是不可取的。複雜模型更容易過擬合，且訓練和維護成本更高。新穎的模型可能尚未經過充分驗證。應根據實際問題和數據選擇最合適的模型，而不是盲目追求複雜或新潮。
    (C) 錯誤。雖然訓練時間是一個需要考慮的因素，但選擇訓練時間最短的模型並不一定能得到最佳的性能。有時，訓練時間較長但性能更好的模型可能是更優的選擇，需要在效率和效果之間進行權衡。
    (D) 錯誤。程式碼的多少與模型的適用性和性能沒有直接關係。選擇模型應基於其解決問題的能力和對數據的擬合程度，而不是其實現的程式碼長短。


36. **題目**：機器學習模型中的「超參數 (Hyperparameters)」與「參數 (Parameters)」有何不同？
    (A) 超參數是模型從數據中學習得到的，參數是在訓練前手動設定的
    (B) 參數是模型從數據中學習得到的，超參數是在訓練前手動設定的，用於控制學習過程
    (C) 兩者沒有本質區別，可以互換使用
    (D) 超參數僅存在於深度學習模型中
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，在機器學習中，「參數」與「超參數」是兩個截然不同的概念：
        -   **參數 (Parameters)**：是模型內部的變量，在訓練過程中從數據中學習並優化得到的。例如，線性迴歸中的係數、神經網絡中的權重和偏置等。這些參數直接影響模型對新數據的預測結果，是通過最小化損失函數（如梯度下降）來自動求解的。
        -   **超參數 (Hyperparameters)**：是模型外部的設置，需要在訓練前由人工設定，用於控制學習算法本身的行為。超參數不是從數據中學習得到的，而是需要通過經驗、嘗試或系統性的調參技術（如網格搜索、隨機搜索）來確定。常見的超參數包括：學習率、正則化系數、神經網絡的層數和每層神經元數量、決策樹的最大深度、集成學習中的基學習器數量等。
    (A) 錯誤。該選項將參數和超參數的定義顛倒了。超參數是需要人工設定的，而不是從數據中學習得到的；參數則是模型在訓練過程中學習得到的，而不是手動設定的。
    (C) 錯誤。參數和超參數有本質的區別：一個是模型自動學習的，另一個是人工設定的；一個直接構成模型本身，另一個控制學習過程；它們絕不能互換使用。
    (D) 錯誤。超參數不僅存在於深度學習模型中，幾乎所有機器學習算法都有超參數。例如，決策樹的最大深度、支持向量機的核參數、K-近鄰的K值等，都是這些傳統機器學習算法的超參數。

37. **題目**：奧卡姆剃刀原則 (Occam's Razor) 在模型選擇中的啟示是什麼？
    (A) 應選擇最複雜的模型，因為它能擬合更多細節
    (B) 若有多個模型都能很好地解釋數據，應選擇結構最簡單的那個模型，以避免過擬合並提高泛化能力
    (C) 模型的簡單與複雜程度與其性能無關
    (D) 應選擇訓練數據量最大的模型
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，奧卡姆剃刀原則 (Occam's Razor) 是一個古老的哲學原則，其核心思想是「如無必要，勿增實體」("Entities should not be multiplied without necessity")，或者更通俗地說，「若有多種方案，應選最簡單的那一個」。在機器學習和模型選擇中，這一原則的應用啟示是：
        -   當有多個模型都能很好地擬合和解釋同一組數據時，應該選擇結構最簡單、最易解釋的那個模型。
        -   越複雜的模型（例如，有更多參數、更深的層次）可能會帶來過擬合的風險，即模型過於複雜，不僅學習了數據中的真實模式，還學習了數據中的噪音和隨機波動，從而導致在新數據上的泛化性能下降。
        -   簡單模型通常有更好的泛化能力，更健壯，更易於理解和解釋，計算成本更低，且不易出現過擬合。
        在機器學習實踐中，這一原則常被用於模型正則化（如L1、L2正則化）和模型選擇（如基於交叉驗證的模型選擇）。
    (A) 錯誤。這與奧卡姆剃刀原則相反。最複雜的模型雖然可能在訓練數據上擬合得更好，但很可能會過擬合，導致在未見數據上表現不佳。奧卡姆剃刀原則提醒我們在解釋力相當的情況下，應選擇最簡單的模型。
    (C) 錯誤。模型的簡單與複雜程度與其性能有重要關係。過於簡單的模型可能欠擬合（無法捕捉數據中的複雜模式），而過於複雜的模型可能過擬合（學習了噪音，泛化能力差）。奧卡姆剃刀原則就是指導我們在這之間找到平衡點。
    (D) 錯誤。訓練數據量的大小與模型選擇是兩個不同的概念。奧卡姆剃刀原則涉及的是模型的複雜度，而不是數據量的大小。雖然更大的訓練數據集通常有助於訓練更複雜的模型而不至於過擬合，但這不是奧卡姆剃刀原則的核心啟示。

38. **題目**：在設計深度神經網路架構時，增加網路的深度（層數）或寬度（每層神經元數量）可能會帶來什麼影響？
    (A) 總是能提高模型性能，且不會有任何負面影響
    (B) 可能增強模型的表達能力以學習更複雜的模式，但也可能增加過擬合的風險和計算成本
    (C) 只會增加計算成本，對模型性能沒有影響
    (D) 會使模型更容易欠擬合
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，在設計深度神經網路架構時，增加網路的深度（層數）或寬度（每層神經元數量）會對模型產生多方面的影響：
        -   **增強表達能力**：更深或更寬的網路有更強的表達能力，能夠學習和建模更複雜的函數關係和數據模式。理論上，增加神經網路的深度可以使其有效地學習更加抽象和複雜的特徵層次結構。
        -   **過擬合風險**：然而，過於複雜的網路（太深或太寬）也更容易過擬合訓練數據，尤其是當訓練數據量有限時。過擬合的模型在訓練數據上表現很好，但在新的、未見過的數據上泛化能力差。
        -   **計算成本**：更深或更寬的網路意味著更多的參數和更複雜的計算圖，這會增加訓練和推斷的計算成本、記憶體需求和訓練時間。
        -   **優化挑戰**：非常深的網路可能面臨梯度消失或梯度爆炸等訓練難題，使得網路難以有效學習。雖然像批標準化、殘差連接這樣的技術可以緩解這些問題，但優化非常深的網路仍然是一個挑戰。

        因此，在設計神經網路架構時，需要在模型複雜度（表達能力）和避免過擬合（泛化能力）之間找到平衡，同時考慮計算資源的限制和優化的可行性。實踐中，常常需要通過實驗和驗證來確定最適合特定問題的網路深度和寬度。
    (A) 錯誤。增加網路的深度或寬度並不總是能提高模型性能，尤其是當這導致過擬合或優化困難時。此外，增加計算成本、訓練時間、記憶體需求等也是明顯的負面影響。
    (C) 錯誤。增加網路的深度或寬度不僅會增加計算成本，還會影響模型的表達能力和性能。適當增加複雜度可以提升模型的能力，使其能夠學習更複雜的模式和特徵。
    (D) 錯誤。增加網路的深度或寬度通常會增加模型的表達能力，使其能夠擬合更複雜的函數。這反而會減少欠擬合的風險（欠擬合是指模型過於簡單，無法捕捉數據中的模式）。過度增加複雜度可能導致的問題是過擬合，而不是欠擬合。

39. **題目**：當面臨一個新的機器學習問題時，一個好的起始策略是什麼？
    (A) 直接嘗試最複雜的深度學習模型
    (B) 從一個或多個簡單的基線模型 (baseline model) 開始，逐步迭代，並根據評估結果決定是否嘗試更複雜的模型
    (C) 花費所有時間在數據收集上，不進行模型實驗
    (D) 隨機選擇一個模型進行訓練
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，在面對一個新的機器學習問題時，一個好的起始策略是從簡單開始，逐步迭代：
        -   **建立基線模型 (baseline model)**：首先實現一個或多個簡單、快速的基線模型，如線性迴歸、決策樹或簡單的神經網路。這些基線模型可以快速實現，提供初步的性能基準，並幫助理解問題的難度和特性。
        -   **分析基線模型**：評估基線模型的性能，分析其錯誤模式，理解模型的局限性，這可能揭示需要改進的方向（例如，需要更多特徵、更複雜的模型架構或更好的數據預處理）。
        -   **逐步迭代**：基於評估結果和分析，逐步改進模型，可能是添加更多特徵、調整超參數、嘗試不同的算法、增加模型複雜度等。每次迭代都應評估模型性能的變化，以確定改進是否有效。
        -   **嘗試更複雜模型**：只有當簡單模型已經被充分探索並顯示出局限性時，才考慮嘗試更複雜的模型。這種漸進式方法可以避免不必要的複雜性和計算資源浪費。
        
        這種「由簡到繁」的迭代方法有助於更好地理解問題和數據，避免直接跳到複雜模型可能帶來的過擬合風險和解釋困難，同時也更有效率地利用時間和計算資源。
    (A) 錯誤。直接嘗試最複雜的深度學習模型不是一個好的起始策略，因為：1）複雜模型需要更多的數據、時間和計算資源；2）如果沒有適當的基線作為比較，難以評估複雜模型的效果是否真的必要；3）複雜模型更容易過擬合，特別是當數據量不足時；4）複雜模型的調試和解釋也更困難。
    (C) 錯誤。雖然高質量的數據對機器學習至關重要，但一個好的策略應該是數據收集和模型實驗的平衡。過早花費過多時間在數據收集上，而不進行任何模型實驗，可能會導致收集了不必要的或不適合問題的數據。透過早期的模型實驗，可以更好地理解哪些數據是真正有用的，哪些特徵是關鍵的。
    (D) 錯誤。隨機選擇一個模型進行訓練是一種非系統化的方法，可能會浪費時間和資源在不適合的模型上，而忽略了可能更適合的簡單解決方案。模型選擇應該基於問題類型、數據特性和性能要求等因素，而不是隨機選擇。

40. **題目**：在機器學習中，將數據集劃分為訓練集 (Training Set)、驗證集 (Validation Set) 和測試集 (Test Set) 的目的是什麼？
    (A) 訓練集用於訓練模型，驗證集用於調整超參數和模型選擇，測試集用於最終評估模型的泛化能力
    (B) 三個集合都可以混合用於模型訓練
    (C) 驗證集和測試集是可選的，僅使用訓練集即可
    (D) 測試集用於模型訓練，訓練集用於模型評估
    **答案**：A
    **詳解**：
    (A) 正確。根據知識文件，在機器學習中，數據集通常被劃分為訓練集、驗證集和測試集，它們各自有不同的目的和用途：
        -   **訓練集 (Training Set)**：用於訓練模型，即模型從這部分數據中學習參數（例如，神經網路的權重、線性迴歸的係數）。訓練集通常佔據總數據集的最大部分（如70%）。
        -   **驗證集 (Validation Set)**：用於在訓練過程中評估模型性能，調整超參數（如學習率、正則化係數、模型架構等），以及在多個候選模型之間進行選擇。驗證集不參與模型的直接訓練，但其性能反饋會間接影響模型的選擇和優化。驗證集通常佔總數據集的一小部分（如15-20%）。
        -   **測試集 (Test Set)**：用於在模型訓練和選擇完成後，對最終選定的模型進行無偏的性能評估，估計模型在真實世界新數據上的泛化能力。測試集在整個訓練和調參過程中都不應該被使用，只在最後進行一次評估。測試集通常也佔總數據集的一小部分（如10-15%）。
        
        這種劃分的主要目的是避免過擬合並獲得對模型泛化能力的可靠估計。如果僅使用同一個數據集進行訓練和評估，模型可能會過度適應該數據集的特性（包括其中的噪音），導致在新數據上表現不佳。通過使用獨立的驗證集調整超參數，使用獨立的測試集評估最終性能，可以更準確地了解模型在未見過的數據上的表現。
    (B) 錯誤。這三個集合有不同的用途，不應混合使用於模型訓練。訓練集用於學習模型參數，驗證集用於超參數調整和模型選擇，測試集用於最終的無偏評估。如果混合使用，就會導致「數據洩露」(data leakage)，使得模型可能過擬合，泛化能力評估也不可靠。
    (C) 錯誤。雖然在某些簡單的場景或資源有限的情況下，可能只使用訓練集和測試集（通過交叉驗證在訓練集中劃分出「折內驗證集」），但驗證集和測試集在嚴謹的機器學習實踐中是不可或缺的。僅使用訓練集既無法調整超參數，也無法可靠評估模型的泛化能力。
    (D) 錯誤。這與正確的數據劃分完全相反。測試集是用於最終評估模型，絕不應用於模型訓練，否則會導致嚴重的過擬合和評估偏差。

**L23303 模型訓練、評估與驗證**

41. **題目**：對於一個二元分類問題，若模型將所有正樣本都正確預測為正，但同時也將許多負樣本錯誤預測為正，則下列哪個評估指標會較高，哪個會較低？
    (A) 召回率 (Recall) 較高，精確率 (Precision) 較低
    (B) 精確率 (Precision) 较高，召回率 (Recall) 较低
    (C) 準確率 (Accuracy) 和 F1 分數都會很高
    (D) 召回率 (Recall) 和精確率 (Precision) 都會很低
    **答案**：A
    **詳解**：
    (A) 正確。根據知識文件，在二元分類問題中，各項評估指標的定義如下：
        -   **召回率 (Recall)** = TP / (TP + FN)，又稱為靈敏度(Sensitivity)，衡量的是模型識別出所有實際正樣本的能力，即「在所有實際為正的樣本中，有多少被正確預測為正」。
        -   **精確率 (Precision)** = TP / (TP + FP)，衡量的是模型預測為正的結果的可信度，即「在所有被預測為正的樣本中，有多少實際是正的」。
        
        根據題目描述，模型將「所有正樣本都正確預測為正」，意味著沒有假陰性(FN=0)，因此召回率 = TP / (TP + 0) = 1，即達到100%的召回率，非常高。
        
        但同時，模型「將許多負樣本錯誤預測為正」，意味著有大量的假陽性(FP)，因此精確率 = TP / (TP + 大量FP)會大幅降低。
        
        這種情況在實際應用中很常見，例如，一個過於「寬鬆」的疾病診斷模型可能將所有病患都檢測出來（高召回率），但同時也會誤將許多健康人視為病患（低精確率）。這體現了分類模型中精確率和召回率之間的權衡關係。
    (B) 錯誤。如果模型將許多負樣本錯誤預測為正(高FP)，則精確率 = TP / (TP + FP) 會較低，而不是較高。
    (C) 錯誤。在這種情況下，F1分數（精確率和召回率的調和平均）不一定會很高，因為雖然召回率高，但精確率低，而F1分數會受到兩者中較低值的強烈影響。至於準確率，如果負樣本佔很大比例，且大量負樣本被誤分為正，那麼準確率也會受到影響而降低。
    (D) 錯誤。根據題目描述，召回率應該很高（因為所有正樣本都被正確預測），而不是很低。

42. **題目**：ROC 曲線 (Receiver Operating Characteristic Curve) 的橫軸和縱軸分別代表什麼？曲線下面積 (AUC) 的意義是什麼？
    (A) 橫軸：真陽性率 (TPR)，縱軸：假陽性率 (FPR)；AUC 越大模型性能越差
    (B) 橫軸：假陽性率 (FPR)，縱軸：真陽性率 (TPR)；AUC 越大模型區分正負樣本的能力越強
    (C) 橫軸：精確率，縱軸：召回率；AUC 代表模型的訓練速度
    (D) 橫軸：樣本數量，縱軸：模型準確率；AUC 代表模型的複雜度
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，ROC曲線(Receiver Operating Characteristic Curve)是二元分類問題中評估模型性能的一種重要工具，特別是在不同閾值設置下模型的表現：
        -   **橫軸**：假陽性率(FPR) = FP / (FP + TN)，又稱為「1 - 特異性」(1 - Specificity)，即「在所有實際為負的樣本中，被錯誤預測為正的比例」。
        -   **縱軸**：真陽性率(TPR) = TP / (TP + FN)，也就是召回率(Recall)或靈敏度(Sensitivity)，即「在所有實際為正的樣本中，被正確預測為正的比例」。
        
        ROC曲線是通過在不同的分類閾值下計算TPR和FPR，然後將這些點連接起來所得到的曲線。理想的分類器會趨近於左上角（高TPR，低FPR）。
        
        **AUC (Area Under the Curve)**是ROC曲線下的面積，取值範圍在0到1之間：
        -   AUC = 1：表示完美分類器，能夠100%區分正負樣本。
        -   AUC = 0.5：表示隨機猜測的分類器，不具有任何區分能力。
        -   AUC < 0.5：表現比隨機猜測還差，通常不會出現，如果出現可能意味著標籤被顛倒了。
        
        AUC可以解釋為：從所有正樣本中隨機選擇一個，從所有負樣本中隨機選擇一個，分類器正確區分這兩個樣本的概率。因此，AUC越大，說明模型區分正負樣本的能力越強。
        
        AUC的一個重要優點是它對類別分佈不均衡不敏感，這使得它在處理不平衡數據集時特別有用。
    (A) 錯誤。ROC曲線的橫軸和縱軸描述是錯誤的，且AUC越大，模型性能越好，而不是越差。
    (C) 錯誤。描述的是PR曲線(Precision-Recall Curve)的軸，而非ROC曲線。此外，AUC不代表模型的訓練速度，而是衡量分類器性能的指標。
    (D) 錯誤。ROC曲線的軸描述完全錯誤，且AUC不代表模型的複雜度，它是分類性能的度量。

43. **題目**：在迴歸問題中，均方誤差 (Mean Squared Error, MSE) 是常用的評估指標，它如何衡量模型的性能？
    (A) MSE 越大，表示模型的預測越接近真實值
    (B) MSE 計算的是預測值與真實值之差的絕對值的平均，數值越小模型性能越好
    (C) MSE 計算的是預測值與真實值之差的平方的平均，數值越小模型性能越好
    (D) MSE 僅用於分類問題
    **答案**：C
    **詳解**：
    (C) 正確。根據知識文件，均方誤差(Mean Squared Error, MSE)是迴歸問題中最常用的評估指標之一：
        -   **定義**：MSE計算的是模型預測值與真實值之差（誤差）的平方的平均值。數學表達式為：
            MSE = (1/n) * Σ(ŷᵢ - yᵢ)²，其中ŷᵢ是第i個樣本的預測值，yᵢ是其真實值，n是樣本數量。
        
        -   **解釋**：MSE值越小，表示模型的預測值越接近真實值，即模型性能越好。MSE為0意味著模型完美預測了所有樣本。
        
        -   **特點**：
            -   MSE對較大的誤差特別敏感，因為誤差被平方了，這使得它在存在離群值（異常值）時可能給予過高的懲罰。
            -   MSE是連續可微的，這使得它在基於梯度的優化方法（如梯度下降）中很實用。
            -   MSE的單位是目標變數的單位的平方，這有時會使解釋變得不直觀。
        
        MSE廣泛應用於線性迴歸、神經網路等各種迴歸模型的訓練和評估中，通常作為損失函數或性能指標。
    (A) 錯誤。MSE越小，而不是越大，表示模型的預測越接近真實值。MSE是誤差的平方和的平均，因此越小代表誤差越小，模型表現越好。
    (B) 錯誤。這描述的是平均絕對誤差(Mean Absolute Error, MAE)，而不是MSE。MAE計算的是預測值與真實值之差的絕對值的平均，而MSE計算的是差的平方的平均。
    (D) 錯誤。MSE主要用於迴歸問題，而不是分類問題。分類問題通常使用準確率(Accuracy)、精確率(Precision)、召回率(Recall)、F1分數、交叉熵損失(Cross-Entropy Loss)等指標。

44. **題目**：混淆矩陣 (Confusion Matrix) 提供了關於分類模型預測結果的詳細信息，它通常不直接包含下列哪個值？
    (A) 真陽性 (True Positives, TP)
    (B) 假陽性 (False Positives, FP)
    (C) 假陰性 (False Negatives, FN)
    (D) 模型的訓練時間 (Training Time)
    **答案**：D
    **詳解**：
    (D) 正確。根據知識文件，混淆矩陣(Confusion Matrix)是評估分類模型性能的一種工具，它以表格形式展示模型預測結果與真實標籤之間的對比關係：
        -   在二元分類問題中，混淆矩陣是一個2×2的表格，包含以下四個基本值：
            -   **真陽性(True Positives, TP)**：實際為正且被正確預測為正的樣本數量。
            -   **真陰性(True Negatives, TN)**：實際為負且被正確預測為負的樣本數量。
            -   **假陽性(False Positives, FP)**：實際為負但被錯誤預測為正的樣本數量，也稱為「第一類錯誤」或「虛假警報」。
            -   **假陰性(False Negatives, FN)**：實際為正但被錯誤預測為負的樣本數量，也稱為「第二類錯誤」或「漏報」。
        
        -   在多類別分類問題中，混淆矩陣是一個n×n的表格，其中n是類別數量。表格的每一行代表一個實際類別，每一列代表一個預測類別。
        
        混淆矩陣不直接包含「模型的訓練時間(Training Time)」這一信息。訓練時間是關於模型訓練過程的度量，而不是模型預測性能的組成部分。混淆矩陣專注於模型預測結果與真實標籤的比較，而不關注模型如何訓練或訓練花費了多少時間。
        
        基於混淆矩陣，可以計算許多重要的評估指標，如精確率(Precision)、召回率(Recall)、F1分數、準確率(Accuracy)、特異性(Specificity)等，但這些都是基於TP、TN、FP、FN計算得到的，而不是混淆矩陣本身直接包含的值。
    (A) 錯誤。真陽性(TP)是混淆矩陣的基本組成部分，它代表實際為正且被正確預測為正的樣本數量。
    (B) 錯誤。假陽性(FP)是混淆矩陣的基本組成部分，它代表實際為負但被錯誤預測為正的樣本數量。
    (C) 錯誤。假陰性(FN)是混淆矩陣的基本組成部分，它代表實際為正但被錯誤預測為負的樣本數量。

45. **題目**：為何在模型評估時，僅僅依賴訓練集上的性能指標是不夠的？
    (A) 因為訓練集上的指標通常難以計算
    (B) 因為模型可能在訓練集上過擬合，導致其在未見數據上的泛化能力不佳，測試集或驗證集上的性能更能反映真實情況
    (C) 因為訓練集數據量太小
    (D) 因為訓練集上的指標與模型的真實性能無關
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，在機器學習中，僅依賴訓練集上的性能指標評估模型是不夠的，主要原因如下：
        -   **過擬合風險**：模型通過訓練過程直接「看到」並學習了訓練集中的數據，可能會過度適應訓練數據的特性，包括其中的噪聲。這種情況稱為過擬合(Overfitting)。一個過擬合的模型在訓練集上表現極佳，但在未見過的新數據上表現可能很差，缺乏泛化能力。
        
        -   **泛化能力評估**：機器學習的核心目標是開發能夠對新的、未見過的數據做出準確預測的模型，而不僅僅是對訓練數據做好。因此，我們需要在模型訓練過程中沒有「看到」的獨立測試集或驗證集上評估模型性能，以真實反映模型的泛化能力。
        
        -   **模型選擇與調參**：在比較不同模型或調整超參數時，僅依賴訓練集指標可能會導致選擇過於複雜、過擬合的模型。使用獨立的驗證集來指導模型選擇和超參數調整是防止這種偏差的重要手段。
        
        -   **現實應用中的性能**：在實際應用中，模型將面對全新的數據。訓練集上的性能指標可能過於樂觀，不能反映模型在實際部署環境中的真實表現。
        
        因此，標準的機器學習實踐是將數據集劃分為訓練集、驗證集和測試集，或使用交叉驗證等技術，確保模型的評估是在獨立數據上進行的，從而獲得對模型泛化能力的客觀評估。
    (A) 錯誤。訓練集上的性能指標通常很容易計算，與在驗證集或測試集上計算性能指標的方法基本相同。困難的不是計算，而是這些指標可能不能真實反映模型的泛化能力。
    (C) 錯誤。訓練集的大小不是主要問題。即使訓練集很大，如果模型只在訓練數據上評估，仍然可能無法反映其在新數據上的表現。此外，在許多實際應用中，訓練集通常比驗證集和測試集大得多。
    (D) 錯誤。訓練集上的指標並非與模型的真實性能「無關」，它們提供了有關模型學習能力的信息。但問題是，單獨的訓練集指標可能過於樂觀，不能完全代表模型的泛化能力或「真實」性能。它們是評估的一部分，但不應是唯一依據。

**L23304 模型調整與優化**

46. **題目**：超參數調整 (Hyperparameter Tuning) 的目的是什麼？
    (A) 調整模型從數據中學習到的內部參數
    (B) 找到一組能夠使模型在驗證集上性能最佳的超參數配置
    (C) 增加訓練數據的數量
    (D) 簡化模型的架構
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，超參數調整 (Hyperparameter Tuning) 是機器學習模型開發過程中的重要步驟，其主要目的是：
        -   **尋找最佳配置**：通過系統性地搜索和評估不同的超參數組合，找到一組能夠使模型在驗證集上性能最佳的超參數配置。
        
        -   **優化模型性能**：超參數控制著模型的複雜度、學習速率和正則化程度等方面，恰當的超參數設置可以顯著提升模型的性能和泛化能力。
        
        -   **平衡欠擬合與過擬合**：超參數調整可以幫助找到一個平衡點，使模型既能充分學習訓練數據中的模式（避免欠擬合），又不會過度拘泥於訓練數據的細節和噪聲（避免過擬合）。
        
        超參數是在模型訓練開始前需要設置的參數，如學習率、正則化係數、神經網絡的層數和每層的神經元數量、決策樹的最大深度等，它們不是通過模型從數據中學習得到的，而是需要人工設定或通過特定的調參技術來確定。
        
        而參數是模型在訓練過程中從數據學習到的變量，如神經網絡的權重和偏置、線性模型的係數等。超參數調整的目的不是直接調整這些參數，而是通過設置適當的超參數，創造一個有利的學習環境，使模型能夠學習到更好的參數。
    (A) 錯誤。超參數調整不是調整模型從數據中學習到的內部參數（如神經網絡的權重、線性模型的係數等）。這些內部參數是通過模型訓練過程自動學習的，而超參數是控制這個學習過程本身的外部設置。
    (C) 錯誤。增加訓練數據的數量是數據收集或增強的任務，與超參數調整無直接關係。雖然更多的訓練數據通常有助於提升模型性能，但這不是超參數調整的目的或方法。
    (D) 錯誤。簡化模型架構可能是模型設計或修改的一個目標，但不是超參數調整的主要目的。有時，超參數調整可能導致選擇更簡單的模型（例如，較低的決策樹深度或較強的正則化），但這只是可能的結果之一，而不是超參數調整本身的目的。

47. **題目**：網格搜索 (Grid Search) 和隨機搜索 (Random Search) 是兩種常用的超參數調整方法，它們的主要區別是什麼？
    (A) 網格搜索比隨機搜索更快找到最優解
    (B) 網格搜索嘗試所有預先定義的超參數組合，而隨機搜索在給定範圍內隨機抽樣組合進行嘗試
    (C) 隨機搜索僅適用於特定類型的模型
    (D) 網格搜索不需要驗證集
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，網格搜索 (Grid Search) 和隨機搜索 (Random Search) 是兩種常用的超參數調整方法，它們的主要區別在於搜索策略：
        -   **網格搜索 (Grid Search)**：
            -   在每個超參數的預定義取值集合上進行系統性的窮舉搜索。
            -   首先為每個超參數定義一個可能的值集合，然後嘗試這些集合的所有可能組合。
            -   例如，如果有兩個超參數，第一個有3個可能值，第二個有4個可能值，則網格搜索會嘗試所有3×4=12個組合。
            -   優點：徹底、系統性強，保證能夠檢查所有指定的超參數組合。
            -   缺點：計算成本高，「維度災難」問題嚴重（當超參數數量增加時，組合數呈指數增長）。

        -   **隨機搜索 (Random Search)**：
            -   在超參數的預定義範圍內隨機抽樣組合進行嘗試，而不是系統地嘗試所有組合。
            -   為每個超參數定義一個分佈（如均勻分佈、對數均勻分佈等），然後從這些分佈中隨機抽樣，組成超參數組合。
            -   通常指定一個總的嘗試次數，而不是嘗試所有可能的組合。
            -   優點：計算效率高，對「維度災難」問題較不敏感，且在實踐中往往能比網格搜索更快找到好的解。
            -   缺點：由於隨機性，可能會漏掉某些可能的最優組合。

        研究表明，當大多數超參數對模型性能的影響相對較小，只有少數超參數真正重要時，隨機搜索通常比網格搜索更有效率，因為它可以用相同數量的嘗試在重要的維度上進行更細致的探索。
    (A) 錯誤。在實踐中，隨機搜索通常比網格搜索更快找到良好的超參數配置，特別是當超參數空間維度較高，且只有少數超參數對結果有顯著影響時。這是因為隨機搜索更有效地探索高維空間，而不會被不重要的維度「浪費」資源。
    (C) 錯誤。隨機搜索是一種通用的超參數調整方法，適用於各種類型的機器學習模型，如線性模型、決策樹、支持向量機、神經網絡等。它不限於特定類型的模型。
    (D) 錯誤。無論是網格搜索還是隨機搜索，都需要某種形式的驗證集來評估不同超參數配置的性能。驗證集（或交叉驗證）是超參數調整過程的核心部分，用於選擇最佳的超參數配置。

48. **題目**：L1 正規化 (L1 Regularization, Lasso) 和 L2 正規化 (L2 Regularization, Ridge) 都可以用來防止模型過擬合，L1 正規化相較於L2正規化，額外具有什麼特性？
    (A) L1 正規化會使權重參數趨向於更大的值
    (B) L1 正規化傾向於產生稀疏權重 (使部分權重變為零)，從而實現特徵選擇的效果
    (C) L1 正規化對異常值更不敏感
    (D) L1 正規化只能用於線性模型
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，L1 正規化 (L1 Regularization，也稱為 Lasso Regularization) 和 L2 正規化 (L2 Regularization，也稱為 Ridge Regularization) 都是常用的防止模型過擬合的技術，它們通過在損失函數中添加權重參數的懲罰項來實現。L1 正規化相較於 L2 正規化，最顯著的額外特性是：
        
        -   **產生稀疏權重 (Sparsity)**：L1 正規化的數學形式是將所有權重參數的絕對值之和作為懲罰項加入損失函數。這種懲罰方式會趨向於使一些參數變為精確的零，而保留其他參數的非零值，從而產生稀疏的權重向量。
        
        -   **內建特徵選擇 (Feature Selection)**：由於 L1 正規化能夠使不重要特徵的權重變為零，它實際上執行了一種內建的特徵選擇功能。只有那些對預測目標有顯著貢獻的特徵才會保留非零權重，這使得模型更加簡潔，也增強了可解釋性。
        
        相比之下，L2 正規化懲罰的是權重參數的平方和，它會使權重值變小（趨向於零）但通常不會變成精確的零。L2 正規化產生的是權重值均勻減小的效果，而不是稀疏化效果。
        
        在處理高維數據且特徵間可能存在冗餘的情況下，L1 正規化的稀疏性和特徵選擇能力特別有用，它可以自動識別並移除冗餘或不相關的特徵，從而簡化模型並可能提高泛化能力。
    (A) 錯誤。L1 正規化不會使權重參數趨向於更大的值，恰恰相反，它傾向於使權重參數變小，甚至變為零。這是因為 L1 正規化在損失函數中添加了權重絕對值之和的懲罰項，模型在優化過程中為了減小這一懲罰，會嘗試減小權重值。
    (C) 錯誤。通常認為 L1 正規化對異常值更敏感而非更不敏感。L1 損失函數（如絕對誤差）確實對異常值比 L2 損失（如平方誤差）更健壯，但 L1 正規化作為一種懲罰項，其對模型參數的影響與異常值敏感性沒有直接關係。
    (D) 錯誤。雖然 L1 正規化在線性模型（如線性迴歸、邏輯迴歸）中最為常見，但它也可以應用於各種非線性模型，包括神經網絡、支持向量機等。例如，在神經網絡中，可以將 L1 正規化應用於權重參數，以促進網絡的稀疏性和特徵選擇。

49. **題目**：早停法 (Early Stopping) 是一種在模型訓練過程中防止過擬合的技術，其基本原理是什麼？
    (A) 在模型訓練達到預設的最大迭代次數時停止
    (B) 監控模型在驗證集上的性能，當驗證集性能不再提升或開始下降時，提前終止訓練
    (C) 僅訓練模型的一部分參數
    (D) 在訓練初期就停止訓練，以節省時間
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，早停法 (Early Stopping) 是一種簡單而有效的正則化技術，用於防止機器學習模型在訓練過程中過擬合。其基本原理是：
        
        -   **監控驗證集性能**：在訓練過程中，持續監控模型在獨立驗證集（不參與訓練的數據集）上的性能指標（如損失值、準確率等）。
        
        -   **識別最佳點**：隨著訓練的進行，模型在訓練集上的性能通常會持續改善，但在驗證集上的性能會先改善，然後在某一點達到最佳，之後可能開始惡化（這表明模型開始過擬合）。
        
        -   **提前終止訓練**：當發現驗證集上的性能指標停止改善或開始下降時（通常會設置一個「耐心」參數，即允許多少輪沒有改善），就提前終止訓練過程，避免模型進一步過擬合。
        
        -   **選用最佳模型**：通常會保存驗證集性能最佳時的模型參數，作為最終模型。
        
        早停法之所以有效，是因為它找到了模型泛化能力最佳的訓練階段，避免了模型過度擬合訓練數據的細節和噪聲。它是一種「隱式正則化」方法，不需要顯式地修改損失函數或模型架構，就能達到控制模型複雜度的效果。
        
        此外，早停法還能節省計算資源，因為不需要等待預設的全部訓練迭代完成，一旦發現模型不再改善，就可以停止訓練。
    (A) 錯誤。這描述的是標準的訓練截止條件，而不是早停法。早停法的核心是根據驗證集性能提前結束訓練，而不是等到預設的最大迭代次數。
    (C) 錯誤。這描述的可能是參數凍結（parameter freezing）或遷移學習中的部分微調（partial fine-tuning）等技術，而不是早停法。早停法不涉及選擇性地訓練部分參數，而是關注整個模型的訓練時機。
    (D) 錯誤。早停法不是簡單地在訓練初期就停止，這樣做可能導致欠擬合（模型未能充分學習）。早停法是基於模型在驗證集上的性能變化來決定何時停止，通常是在模型達到最佳泛化能力的點。

50. **題目**：遷移學習 (Transfer Learning) 的核心思想是什麼？它在何種情況下特別有用？
    (A) 將一個任務上學到的知識完全拋棄，從零開始為新任務訓練模型
    (B) 將在一個大規模數據集上預訓練好的模型的部分知識（如特徵提取層）遷移到一個新的、數據量較小的相關任務上，以加速訓練並提升性能
    (C) 僅適用於不同領域之間完全不相關的任務
    (D) 遷移學習會顯著增加模型的訓練時間
    **答案**：B
    **詳解**：
    (B) 正確。根據知識文件，遷移學習 (Transfer Learning) 是機器學習中的一種方法，其核心思想是：
        
        -   **知識遷移**：將從一個任務（源任務）中學到的知識應用到另一個相關但不同的任務（目標任務）上，而不是每次都從頭開始學習。這種「知識遷移」通常體現為重用在源任務上訓練的模型參數（例如神經網絡的權重）或特徵表示。
        
        遷移學習在以下情況下特別有用：
        
        -   **目標任務數據有限**：當目標任務的標記數據非常有限，難以從頭訓練出一個有效的模型時，使用在大規模數據集上預訓練好的模型可以大幅提高學習效率和性能。
        
        -   **源任務與目標任務相關**：當源任務和目標任務之間存在一定的相關性或相似性時，源任務學到的特徵或模式對於目標任務也可能有用。例如，在圖像分類中，低層次的特徵（如邊緣、紋理、形狀等）通常對各種視覺任務都有用。
        
        -   **計算資源有限**：使用遷移學習可以利用已有的預訓練模型，避免從頭開始訓練一個複雜模型所需的大量計算資源。
        
        -   **加速收斂**：即使有足夠的目標任務數據，使用遷移學習也可以加速模型的收斂，縮短訓練時間。
        
        遷移學習的常見實施方式包括：
        -   **特徵提取**：將預訓練模型的前幾層（特徵提取部分）保持不變，只重新訓練最後的分類層或任務特定層。
        -   **微調 (Fine-tuning)**：在源任務的預訓練模型基礎上，用目標任務的數據調整部分或全部參數，通常使用較小的學習率。
        
        在深度學習領域，遷移學習已成為標準做法，特別是在計算機視覺（使用ImageNet預訓練模型）和自然語言處理（使用BERT、GPT等預訓練模型）領域。
    (A) 錯誤。這描述的是從頭開始訓練 (training from scratch)，與遷移學習的概念完全相反。遷移學習的核心正是利用之前學到的知識，而不是完全拋棄它。
    (C) 錯誤。遷移學習在源任務和目標任務相關或相似時效果最好，而不是在它們完全不相關的情況下。當任務間差異過大時，遷移學習的效果可能有限或甚至有害（負遷移）。
    (D) 錯誤。遷移學習通常會顯著減少而不是增加模型的訓練時間。由於可以利用預訓練模型的參數作為良好的初始點，加上可能只需要微調部分參數，遷移學習通常能夠加速收斂，減少達到良好性能所需的訓練時間。

**L234 機器學習治理**

**L23401 數據隱私、安全與合規**

51. **題目**：歐盟的通用數據保護條例 (GDPR) 對個人數據的處理提出了嚴格要求，下列何者不是GDPR強調的核心原則？
    (A) 數據最小化 (Data Minimization)
    (B) 目的限制 (Purpose Limitation)
    (C) 企業可以無限制地收集和共享用戶數據以獲取最大利潤
    (D) 透明性 (Transparency) 與問責性 (Accountability)
    **答案**：C

52. **題目**：數據匿名化 (Data Anonymization) 和假名化 (Pseudonymization) 都是保護數據隱私的方法，它們的主要區別是什麼？
    (A) 匿名化後的數據完全無法追溯到個人，假名化後的數據在特定條件下仍可能透過額外信息重新識別個人
    (B) 假名化比匿名化提供了更強的隱私保護
    (C) 匿名化僅移除直接識別符，假名化移除了所有信息
    (D) 兩者在隱私保護效果上完全相同
    **答案**：A

53. **題目**：對抗性攻擊 (Adversarial Attacks) 是指對機器學習模型輸入進行微小但精心設計的擾動，導致模型做出錯誤預測。這主要威脅到模型的哪個方面？
    (A) 訓練效率
    (B) 模型的穩健性 (Robustness) 與安全性
    (C) 模型的可解釋性
    (D) 模型的部署成本
    **答案**：B

54. **題目**：在機器學習專案中，確保數據在收集、儲存、處理和傳輸過程中的安全性，應採取哪些措施？
    (A) 僅依賴防火牆保護
    (B) 採用加密技術、存取控制、安全審計、以及遵守相關安全標準與法規
    (C) 將所有數據公開，以便進行透明化處理
    (D) 數據安全僅是IT部門的責任，與機器學習團隊無關
    **答案**：B

55. **題目**：模型反演攻擊 (Model Inversion Attack) 試圖從已訓練的機器學習模型中恢復部分或全部訓練數據，這對數據隱私構成了何種威脅？
    (A) 威脅模型的預測準確率
    (B) 可能洩露訓練數據中的敏感個人信息
    (C) 導致模型訓練時間過長
    (D) 僅影響模型的超參數設定
    **答案**：B

**L23402 演算法偏見與公平性**

56. **題目**：機器學習模型中出現演算法偏見 (Algorithmic Bias) 的主要原因不包含下列何者？
    (A) 訓練數據本身存在歷史偏見或代表性不足
    (B) 模型設計或特徵選擇過程中引入的偏見
    (C) 模型使用的硬體計算資源過於強大
    (D) 人類在數據標註或模型評估過程中的主觀偏見
    **答案**：C

57. **題目**：在評估機器學習模型的公平性時，「群體公平性 (Group Fairness)」通常指的是什麼？
    (A) 模型對所有個體的預測都完全準確
    (B) 模型對不同受保護群體（如基於性別、種族）的預測結果或影響應達到某種程度的平等或均衡
    (C) 模型應對所有特徵一視同仁，不考慮其重要性
    (D) 僅關注模型的整體準確率，不考慮不同群體間的差異
    **答案**：B

58. **題目**：可解釋AI (Explainable AI, XAI) 技術為何對於解決演算法偏見與公平性問題至關重要？
    (A) XAI 可以自動消除所有偏見
    (B) 透過理解模型的決策依據，XAI有助於識別和診斷模型中可能存在的偏見來源，並評估其公平性影響
    (C) XAI 會使模型變得更加不透明
    (D) XAI 僅用於提升模型的預測速度
    **答案**：B

59. **題目**：下列哪項措施有助於緩解機器學習模型中的演算法偏見？
    (A) 僅使用來自單一來源的數據進行訓練
    (B) 在數據收集階段確保數據的多樣性與代表性，並在模型開發與評估過程中引入公平性考量與度量
    (C) 刻意選擇會放大偏見的模型架構
    (D) 避免對模型進行任何形式的公平性審計
    **答案**：B

60. **題目**：當一個用於招聘篩選的AI模型，因為訓練數據中男性工程師比例遠高於女性，而傾向於給男性求職者更高的評分時，這體現了何種問題？
    (A) 模型的計算效率不足
    (B) 數據偏見導致的演算法不公平，可能構成性別歧視
    (C) 模型過度依賴單一特徵
    (D) 模型的泛化能力過強
    **答案**：B

