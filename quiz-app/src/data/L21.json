{
    "L21": {
        "title": "人工智慧技術應用與規劃",
        "sections": {
            "L211": {
                "title": "AI 相關技術應用",
                "sub_sections": {
                    "L21101": {
                        "title": "自然語言處理技術與應用",
                        "questions": [
                            {
                                "question_text": "下列何者最能描述自然語言處理（NLP）的核心目標？",
                                "options": {
                                    "A": "讓電腦能夠看懂並分析圖像內容",
                                    "B": "使電腦能夠理解與產生人類語言",
                                    "C": "使電腦能夠從大量數據中找出隱藏的模式和關聯",
                                    "D": "讓電腦能夠自動執行重複性的軟體測試任務"
                                },
                                "correct_answer": "B",
                                "solution": "<div><p><strong>(B) 正確。</strong></p><p>自然語言處理（NLP）的核心目標是讓電腦能夠理解、解釋並生成人類的語言，使其能夠與人類進行有效的溝通或處理基於語言的任務。</p><p><strong>(A)</strong></p><p>讓電腦能夠看懂並分析圖像內容是電腦視覺（Computer Vision, CV）的核心目標。</p><p><strong>(C)</strong></p><p>讓電腦能夠從大量數據中找出隱藏的模式是數據探勘（Data Mining）或機器學習（Machine Learning）的廣泛目標之一，並非NLP獨有的核心目標。</p><p><strong>(D)</strong></p><p>讓電腦能夠自動化重複性的軟體測試流程指的是軟體測試自動化，雖然可能應用AI技術，但並非NLP的核心目標。</p></div>"
                            },
                            {
                                "question_text": "一家電商公司希望分析其網站上數千條客戶對產品的評論，以了解客戶的整體滿意度和主要抱怨點。此情境最適合應用下列哪一項NLP技術？",
                                "options": {
                                    "A": "自動翻譯系統",
                                    "B": "自然語言生成",
                                    "C": "情感分析技術",
                                    "D": "語音轉文字識別"
                                },
                                "correct_answer": "C",
                                "solution": "<div><p><strong>(C) 正確。</strong></p><p>情感分析是自然語言處理(NLP)的一項技術，專門用於識別和提取文本資料中的主觀資訊，例如用戶的情緒、評價、滿意度等。在此情境中，電商公司希望分析客戶評論以了解滿意度和抱怨點，這正是情感分析的典型應用場景。</p><p><strong>(A)</strong></p><p>機器翻譯是指將一種自然語言文本自動轉換為另一種自然語言文本的技術，與分析客戶評論的情感無關。</p><p><strong>(B)</strong></p><p>文本生成是指讓電腦自動產生新的文本內容，例如撰寫新聞摘要或故事，此處的需求是分析現有評論，而非生成新評論。</p><p><strong>(D)</strong></p><p>語音識別是指將人類的語音轉換為文字的技術，而客戶評論通常是以文字形式存在的，因此不適用語音識別。</p></div>"
                            },
                            {
                                "question_text": "在自然語言處理的預處理流程中，「將句子或段落切分成詞彙、標點符號等基本單元」的步驟稱為什麼？",
                                "options": {
                                    "A": "詞形還原(Lemmatization)",
                                    "B": "停用詞處理(Stop-word removal)",
                                    "C": "斷詞 (Tokenization)",
                                    "D": "特徵提取(Feature extraction)"
                                },
                                "correct_answer": "C",
                                "solution": "<div><p><strong>(C) 正確。</strong></p><p>「斷詞 (Tokenization)」是自然語言處理預處理中的一個基本步驟，其目的是將連續的文本序列（如句子或段落）分割成更小的、有意義的單元，這些單元通常是詞彙、數字、標點符號等，稱為「詞元」或「標記」(tokens)。這一步驟對於後續的文本分析至關重要。</p><p><strong>(A)</strong></p><p>詞形還原是指將單詞的不同屈折形式還原為其基本詞形或詞典形式。</p><p><strong>(B)</strong></p><p>停用詞移除是指從文本中移除那些頻繁出現但對語義貢獻不大的詞彙。</p><p><strong>(D)</strong></p><p>特徵提取是指從原始數據中轉換或選擇出對模型有用的特徵，在NLP中可能發生在斷詞之後。</p></div>"
                            },
                            {
                                "question_text": "某新聞機構希望開發一個系統，能自動將長篇新聞報導濃縮成數句摘要。此功能主要依賴下列哪一項NLP技術？",
                                "options": {
                                    "A": "文本分類技術",
                                    "B": "文本摘要生成",
                                    "C": "命名實體辨識",
                                    "D": "文本情感分析"
                                },
                                "correct_answer": "B",
                                "solution": "<div><p><strong>(B) 正確。</strong></p><p>文本生成是自然語言處理的一個分支，其目標是讓電腦能夠自動產生新的、連貫的、有意義的文本內容。自動生成新聞摘要即是文本生成的一種典型應用，系統需要理解原文主旨，然後生成簡潔的摘要。</p><p><strong>(A)</strong></p><p>文本分類是指將文本分配到預定義的類別中，例如將新聞分類為體育、政治、財經等，與生成摘要不同。</p><p><strong>(C)</strong></p><p>命名實體識別是指從文本中識別出具有特定意義的實體，例如人名、地名、組織名等，與生成摘要不同。</p><p><strong>(D)</strong></p><p>情感分析是指分析文本中所表達的情感傾向（如正面、負面、中性），與生成摘要不同。</p></div>"
                            },
                            {
                                "question_text": "TF-IDF (Term Frequency-Inverse Document Frequency) 是一種常用於評估什麼的技術？",
                                "options": {
                                    "A": "詞彙出現頻率",
                                    "B": "詞彙稀有程度",
                                    "C": "詞彙關聯重要性",
                                    "D": "詞彙語法功能"
                                },
                                "correct_answer": "C",
                                "solution": "<div><p><strong>(C) 正確。</strong></p><p>TF-IDF是一種統計方法，用以評估一個詞彙對於一個文件集或一個語料庫中的其中一份文件的重要程度。它結合了詞頻(TF)和逆向文件頻率(IDF)。詞頻表示一個詞彙在單一文件中出現的頻率，而逆向文件頻率則衡量該詞彙在整個文件集中的普遍程度（越普遍，IDF值越低，代表區分度不高）。兩者相乘得到的TF-IDF值越高，代表該詞彙對該文件的鑑別度越高，即越重要。</p><p><strong>(A)</strong></p><p>詞彙在單一文件中的出現頻率只是TF-IDF計算的一部分。</p><p><strong>(B)</strong></p><p>詞彙在整個文件集中的罕見程度也只是TF-IDF計算的一部分。</p><p><strong>(D)</strong></p><p>詞彙的詞性是詞彙的語法屬性，與TF-IDF評估詞彙重要性的功能不同。</p></div>"
                            }
                        ]
                    },
                    "L21102": {
                        "title": "電腦視覺技術與應用",
                        "questions": [
                            {
                                "question_text": "以下哪項不是典型的電腦視覺任務？",
                                "options": {
                                    "A": "影像分類與辨識",
                                    "B": "物體偵測與定位",
                                    "C": "語言內容生成",
                                    "D": "影像區域分割"
                                },
                                "correct_answer": "C",
                                "solution": "<div><p><strong>(C) 正確。</strong></p><p>自然語言生成不是電腦視覺任務，而是自然語言處理（NLP）的一部分。自然語言生成涉及產生人類可理解的文本，例如聊天機器人回應、內容摘要或故事創作。</p><p><strong>(A)</strong></p><p>影像分類是電腦視覺的基本任務，旨在將整個圖像分類為特定類別（如「貓」、「狗」、「汽車」等）。</p><p><strong>(B)</strong></p><p>物體偵測是電腦視覺任務，涉及識別圖像中物體的位置並為其分類。</p><p><strong>(D)</strong></p><p>影像分割是電腦視覺任務，涉及將圖像分割為多個區域，並識別每個像素屬於哪個特定物體或類別。</p></div>"
                            },
                            {
                                "question_text": "一家製造工廠希望導入AI系統，自動檢測生產線上產品的外觀瑕疵。此應用最適合使用下列哪種技術？",
                                "options": {
                                    "A": "語音辨識技術",
                                    "B": "視覺檢測系統",
                                    "C": "文本情感分析",
                                    "D": "語言轉換系統"
                                },
                                "correct_answer": "B",
                                "solution": "<div><p><strong>(B) 正確。</strong></p><p>電腦視覺專長於讓機器「看懂」並解析圖像內容。物體偵測是電腦視覺的一項重要應用，旨在識別圖像中特定物體的位置和類別。在製造工廠自動檢測產品外觀瑕疵的情境中，系統需要「看到」產品並「偵測」出瑕疵，這正是物體偵測（屬於電腦視覺範疇）的典型應用。</p><p><strong>(A)</strong></p><p>語音識別是將人類語音轉換為文字的技術，與檢測產品外觀瑕疵無關。</p><p><strong>(C)</strong></p><p>情感分析是分析文本中所表達的情感傾向，與檢測產品外觀瑕疵無關。</p><p><strong>(D)</strong></p><p>機器翻譯是將一種自然語言文本自動轉換為另一種自然語言文本的技術，與檢測產品外觀瑕疵無關。</p></div>"
                            },
                            {
                                "question_text": "卷積神經網路 (CNN) 因其何種特性而特別適合處理圖像數據？",
                                "options": {
                                    "A": "序列數據處理能力",
                                    "B": "區域特徵擷取能力",
                                    "C": "無監督學習能力",
                                    "D": "圖像創造生成能力"
                                },
                                "correct_answer": "B",
                                "solution": "<div><p><strong>(B) 正確。</strong></p><p>卷積神經網路的核心優勢在於其能夠通過卷積層有效提取圖像的局部特徵（例如邊緣、角點、紋理等）。此外，CNN中的權重共享（參數共享）機制，即在圖像的不同位置使用相同的卷積核，大大減少了模型的參數數量，使其更易於訓練且能更好地泛化。這兩大特性使其在圖像處理任務中表現出色。</p><p><strong>(A)</strong></p><p>能夠有效處理序列數據的時間依賴性是循環神經網路的主要特性。</p><p><strong>(C)</strong></p><p>能夠在沒有標註數據的情況下進行學習指的是無監督學習，CNN最常見應用是在監督學習中。</p><p><strong>(D)</strong></p><p>能夠生成全新的圖像通常是生成式AI模型的特性，CNN主要優勢在於特徵提取。</p></div>"
                            },
                            {
                                "question_text": "在自動駕駛系統中，用以識別路上的行人、車輛、交通號誌等物體的關鍵AI技術是什麼？",
                                "options": {
                                    "A": "語言處理系統",
                                    "B": "視覺識別系統",
                                    "C": "專家規則系統",
                                    "D": "數據儲存系統"
                                },
                                "correct_answer": "B",
                                "solution": "<div><p><strong>(B) 正確。</strong></p><p>電腦視覺專注於讓電腦能夠「看懂」並解析圖像或影片內容。在自動駕駛系統中，識別路上的行人、車輛、交通號誌等物體，需要系統能夠分析來自攝影機等感測器的視覺資訊，這正是電腦視覺的核心應用。自然語言生成是指讓電腦自動產生人類語言文本，與識別道路上的物體無關。專家系統是一種早期的人工智慧程式，模擬人類專家在特定領域的決策能力，雖然自動駕駛系統可能包含規則，但物體識別依賴於電腦視覺。數據庫管理涉及數據的儲存、組織和檢索，不是識別物體的AI技術。</p><p><strong>(A)</strong></p><p>自然語言生成是指讓電腦自動產生人類語言文本，與識別道路上的物體無關。</p><p><strong>(C)</strong></p><p>專家系統是一種早期的人工智慧程式，模擬人類專家在特定領域的決策能力，雖然自動駕駛系統可能包含規則，但物體識別依賴於電腦視覺。</p><p><strong>(D)</strong></p><p>數據庫管理涉及數據的儲存、組織和檢索，不是識別物體的AI技術。</p></div>"
                            },
                            {
                                "question_text": "光學字元辨識 (OCR) 技術的主要功能為何？",
                                "options": {
                                    "A": "圖像文字識別",
                                    "B": "語音內容辨識",
                                    "C": "文本關鍵詞提取",
                                    "D": "影像人臉識別"
                                },
                                "correct_answer": "A",
                                "solution": "<div><p><strong>(A) 正確。</strong></p><p>光學字元辨識技術的主要功能是將圖像中的文字（例如掃描文件、照片中的文字）轉換為機器可讀的文字格式。這使得圖像中的文本可以被編輯、搜尋和處理。</p><p><strong>(B)</strong></p><p>從語音中提取文字是語音識別或語音轉文字技術的功能。</p><p><strong>(C)</strong></p><p>從文本中提取關鍵詞是自然語言處理中的關鍵詞提取任務。</p><p><strong>(D)</strong></p><p>從影片中識別人臉是電腦視覺中的人臉識別或人臉偵測技術，與OCR提取文字的功能不同。</p></div>"
                            },
                            {
                                "question_text": "臉部辨識系統主要涉及下列哪一項電腦視覺任務？",
                                "options": {
                                    "A": "像素區域分割",
                                    "B": "動態行為識別",
                                    "C": "物體移動追蹤",
                                    "D": "物體偵測識別"
                                },
                                "correct_answer": "D",
                                "solution": "<div><p><strong>(D) 正確。</strong></p><p>臉部辨識系統涉及兩個核心步驟：1) 臉部檢測（找出圖像中人臉的位置）；2) 臉部識別（確定檢測到的臉是屬於哪個人）。這兩個步驟分別對應物體檢測和物體識別任務，因此臉部辨識主要涉及「物體檢測與識別」。</p><p><strong>(A)</strong></p><p>物體分割是將圖像區分為多個區域並標記每個像素所屬的類別，雖用於某些高級臉部辨識系統，但不是臉部辨識的主要任務。</p><p><strong>(B)</strong></p><p>動作識別是辨識圖像/影片中的動作，例如走路、跑步等，與臉部辨識不直接相關。</p><p><strong>(C)</strong></p><p>物體追蹤是在視頻序列中跟蹤物體的運動軌跡，雖可用於動態場景中的臉部跟蹤，但不是臉部辨識的主要任務。</p></div>"
                            }
                        ]
                    },
                    "L21103": {
                        "title": "生成式AI技術與應用",
                        "questions": [
                            {
                                "question_text": "下列何者最能體現生成式AI (Generative AI) 的核心特點？",
                                "options": {
                                    "A": "數據精確分類",
                                    "B": "未來事件預測",
                                    "C": "新內容創造能力",
                                    "D": "數據洞察提取"
                                },
                                "correct_answer": "C",
                                "solution": "<div><p><strong>(C) 正確。</strong></p><p>生成式AI的核心特點是其能夠創造全新的、原創的內容，例如生成圖像、文本、音樂、程式碼等。它不是簡單地分析或分類現有數據，而是學習數據中的模式以生成新的、類似的數據。</p><p><strong>(A)</strong></p><p>對現有數據進行精確分類是鑑別式AI或傳統監督式學習分類模型的任務。</p><p><strong>(B)</strong></p><p>預測未來事件發生的機率通常是預測性分析的範疇，這與生成式AI創造新內容的核心特點不同。</p><p><strong>(D)</strong></p><p>從大量數據中提取有價值的洞察是數據探勘或廣義的數據分析的目標，但生成式AI的核心在於「生成」而非僅僅「提取洞察」。</p></div>"
                            },
                            {
                                "question_text": "近期廣受討論的DALL-E、Midjourney等工具，能夠根據用戶的文字描述生成對應的圖像，這屬於下列哪一種AI技術的應用？",
                                "options": {
                                    "A": "識別分類AI",
                                    "B": "創作生成AI",
                                    "C": "強化學習系統",
                                    "D": "傳統機器學習"
                                },
                                "correct_answer": "B",
                                "solution": "<div><p><strong>(B) 正確。</strong></p><p>DALL-E、Midjourney這類工具的核心功能是根據用戶提供的文字描述（prompt）來「創造」和「生成」全新的圖像。這完全符合生成式AI的定義，即能夠產生新內容的AI類型。</p><p><strong>(A)</strong></p><p>鑑別式AI的主要任務是進行分類或預測，例如判斷一張圖片是貓還是狗，而不是創造新內容。</p><p><strong>(C)</strong></p><p>強化學習是一種AI方法，其中智能體透過與環境互動並從中學習，以最大化某種獎勵，與根據描述生成圖像的任務不同。</p><p><strong>(D)</strong></p><p>傳統機器學習是一個廣泛的術語，包含多種算法，這些算法通常用於分類、迴歸、分群等任務，其核心並非專注於從無到有地創造複雜的新內容。</p></div>"
                            },
                            {
                                "question_text": "大型語言模型 (LLMs) 如GPT系列，其強大的文本理解與生成能力主要基於下列何種模型架構？",
                                "options": {
                                    "A": "卷積網路",
                                    "B": "循環網路",
                                    "C": "注意力機制",
                                    "D": "支持向量機"
                                },
                                "correct_answer": "C",
                                "solution": "<div><p><strong>(C) 正確。</strong></p><p>大型語言模型如GPT系列，其突破性的文本理解與生成能力主要歸功於Transformer模型架構。Transformer架構引入了自註意力機制，使其能夠並行處理序列中的所有詞彙，並有效捕捉長距離依賴關係，這對於理解上下文和生成連貫文本至關重要。</p><p><strong>(A)</strong></p><p>卷積神經網路主要用於處理網格狀數據，如圖像，不是大型語言模型的核心架構。</p><p><strong>(B)</strong></p><p>循環神經網路及其變種傳統上用於處理序列數據，但在處理長序列時存在梯度消失/爆炸和難以並行計算的問題，Transformer架構解決了這些問題。</p><p><strong>(D)</strong></p><p>支持向量機是一種經典的監督學習模型，與深度學習模型如Transformer有顯著差異。</p></div>"
                            },
                            {
                                "question_text": "生成對抗網路 (GANs) 通常包含哪兩個主要組成部分？",
                                "options": {
                                    "A": "編碼器與解碼器",
                                    "B": "生成器與判別器",
                                    "C": "卷積層與池化層",
                                    "D": "決策樹與隨機森林"
                                },
                                "correct_answer": "B",
                                "solution": "<div><p><strong>(B) 正確。</strong></p><p>生成對抗網路的核心架構包含兩個相互競爭的神經網路：生成器和判別器。生成器的目標是學習真實數據的分佈並生成新的、看起來真實的數據樣本；判別器的目標是盡可能準確地判斷輸入的數據是來自真實數據集還是由生成器生成的假數據。兩者透過對抗過程共同進化，最終使生成器能夠產生高度逼真的數據。</p><p><strong>(A)</strong></p><p>編碼器與解碼器是自編碼器或序列到序列模型的主要組成部分。</p><p><strong>(C)</strong></p><p>卷積層與池化層是卷積神經網路的關鍵組件。</p><p><strong>(D)</strong></p><p>決策樹與隨機森林是傳統的機器學習算法，與GAN的深度學習神經網路架構有本質區別。</p></div>"
                            },
                            {
                                "question_text": "利用生成式AI產生合成數據以擴充現有訓練數據集，這種做法的主要目的是什麼？",
                                "options": {
                                    "A": "降低計算資源消耗",
                                    "B": "提高模型解釋能力",
                                    "C": "改善小樣本學習效果",
                                    "D": "完全取代真實數據"
                                },
                                "correct_answer": "C",
                                "solution": "<div><p><strong>(C) 正確。</strong></p><p>生成式AI可以創造新的、類似於真實數據的合成數據。當現有訓練數據集規模較小或某些類別的樣本數量遠少於其他類別時，模型的學習效果和泛化能力會受到限制。透過生成合成數據來擴充這些數據集，可以提供更多樣化的訓練樣本，有助於模型更好地學習數據分佈，從而改善其在這些具有挑戰性的數據集上的表現，提升模型的魯棒性和準確性。</p><p><strong>(A)</strong></p><p>產生合成數據本身也需要計算資源，雖然可能間接幫助模型更快收斂，但主要目的不是直接降低訓練資源。</p><p><strong>(B)</strong></p><p>合成數據通常是為了改善模型性能，而不是直接提高模型的解釋性。</p><p><strong>(D)</strong></p><p>合成數據通常不能完全取代真實數據的收集，真實數據仍然是模型學習現實世界模式的基礎。</p></div>"
                            }
                        ]
                    },
                    "L21104": {
                        "title": "多模態人工智慧應用",
                        "questions": [
                            {
                                "question_text": "多模態AI (Multimodal AI) 指的是能夠處理何種資訊的AI技術？",
                                "options": {
                                    "A": "單一類型數據處理",
                                    "B": "多類型數據整合處理",
                                    "C": "時間序列數據分析",
                                    "D": "多風格藝術創作"
                                },
                                "correct_answer": "B",
                                "solution": "<div><p><strong>(B) 正確。</strong></p><p>多模態AI的核心定義是能夠同時處理和整合來自多種不同類型數據源（模態）的資訊。這些模態可以包括文本、圖像、語音、影片、感測器數據等。其目標是讓AI系統能夠更全面地理解複雜情境，就像人類一樣透過多種感官來感知世界。\n\n(A) 僅處理單一類型的數據的AI稱為單模態AI。\n\n(C) 專門處理具有多種模式或趨勢的時間序列數據是時間序列分析的範疇。\n\n(D) 專門用於生成多種風格藝術作品的AI可能屬於生成式AI的範疇，多模態AI更側重於處理和理解多種類型的輸入數據。</p></div>"
                            },
                            {
                                "question_text": "一個AI系統能夠觀看一段影片，並根據影片內容自動生成一段文字描述。這最能體現下列哪種AI技術的應用？",
                                "options": {
                                    "A": "純語言處理",
                                    "B": "純視覺處理",
                                    "C": "跨模態整合處理",
                                    "D": "統計模型分析"
                                },
                                "correct_answer": "C",
                                "solution": "<div><p><strong>(C) 正確。</strong></p><p>多模態AI的核心能力在於能同時處理並整合來自多種不同類型數據源的資訊。在此情境中，AI系統需要處理視覺資訊（觀看影片）並生成文字資訊（文字描述），這涉及到電腦視覺和自然語言處理兩種模態的結合與協同工作，是多模態AI的典型應用。</p><p><strong>(A)</strong></p><p>單模態自然語言處理僅專注於處理單一的語言文字模態，輸入是影片，因此純NLP無法完成此任務。</p><p><strong>(B)</strong></p><p>單模態電腦視覺僅專注於處理單一的視覺圖像或影片模態，雖然系統需要理解影片內容，但它還需要生成文字描述，這超出了純CV的範疇。</p><p><strong>(D)</strong></p><p>傳統統計模型主要處理結構化數據，難以直接應對影片理解並生成複雜文本描述這樣的多模態任務。</p></div>"
                            },
                            {
                                "question_text": "在多模態AI中，將從不同數據類型（如圖像特徵和文本特徵）中提取出來的資訊有效地結合起來，這個過程稱為什麼？",
                                "options": {
                                    "A": "特徵選擇過程",
                                    "B": "特徵融合過程",
                                    "C": "特徵縮放過程",
                                    "D": "特徵編碼過程"
                                },
                                "correct_answer": "B",
                                "solution": "<div><p><strong>(B) 正確。</strong></p><p>在多模態AI中，當系統處理來自不同模態的數據時，會先從各個模態中提取特徵。特徵融合指的是將這些從不同模態提取出來的特徵表示有效地結合或整合起來，形成一個統一的、更豐富的特徵表示，以便後續的聯合學習或決策。這是多模態學習中的關鍵步驟。</p><p><strong>(A)</strong></p><p>特徵選擇是指從現有的特徵集合中選擇出一個子集，以去除不相關或冗餘的特徵，通常在單一模態或已融合的特徵上進行。</p><p><strong>(C)</strong></p><p>特徵縮放是一種數據預處理技術，用於將不同範圍的數值特徵調整到相似的尺度，與結合不同模態特徵無關。</p><p><strong>(D)</strong></p><p>特徵編碼是指將原始數據轉換為機器學習模型可以處理的數值格式的過程，處理的是單一特徵的表示形式，而不是不同模態特徵的結合。</p></div>"
                            },
                            {
                                "question_text": "視覺問答系統允許用戶針對一張圖片提出問題，並由AI系統回答。此類系統是哪種AI技術的典型應用？",
                                "options": {
                                    "A": "純視覺處理技術",
                                    "B": "純語言處理技術",
                                    "C": "跨模態整合技術",
                                    "D": "行為強化學習"
                                },
                                "correct_answer": "C",
                                "solution": "<div><p><strong>(C) 正確。</strong></p><p>視覺問答系統需要理解圖像內容（電腦視覺）和用戶提出的自然語言問題（自然語言處理），然後結合這兩方面的信息來生成答案。這種同時處理和整合圖像與文本兩種不同模態資訊的能力，正是多模態AI的核心特徵和典型應用。</p><p><strong>(A)</strong></p><p>僅依賴電腦視覺的系統可以分析圖像內容，但無法理解用戶提出的自然語言問題或生成自然語言答案。</p><p><strong>(B)</strong></p><p>僅依賴自然語言處理的系統可以理解和生成文本，但無法理解圖像內容。</p><p><strong>(D)</strong></p><p>強化學習是一種AI方法，其中智能體透過與環境互動學習以最大化獎勵，與視覺問答這種需要理解多種感官輸入並生成答案的任務不同。</p></div>"
                            },
                            {
                                "question_text": "下列何者不是多模態AI的典型應用場景？",
                                "options": {
                                    "A": "圖像內容描述生成",
                                    "B": "多源數據情感分析",
                                    "C": "跨媒體內容檢索",
                                    "D": "單一類型數據預測"
                                },
                                "correct_answer": "D",
                                "solution": "<div><p><strong>(D) 正確。</strong></p><p>僅使用歷史銷售數據（通常是結構化的數值數據）來預測未來一周的產品銷量，這是一個典型的時間序列預測或迴歸分析任務，屬於單模態數據分析的範疇，不涉及多種不同類型數據源的整合，因此不是多模態AI的典型應用場景。</p><p><strong>(A)</strong></p><p>根據圖像內容生成文字描述是多模態AI的典型應用，它需要理解圖像（視覺模態）並生成文本（語言模態）。</p><p><strong>(B)</strong></p><p>結合語音語調、面部表情和文本內容進行情感分析，是多模態情感分析的典型應用，它整合了多種數據源來更準確地判斷情感。</p><p><strong>(C)</strong></p><p>使用文本查詢來檢索相關的圖像是多模態AI的典型應用，它需要理解文本查詢的語義並在圖像數據庫中找到與之匹配的視覺內容。</p></div>"
                            }
                        ]
                    }
                }
            },
            "L212": {
                "title": "AI 導入評估規劃",
                "sub_sections": {
                    "L21201": {
                        "title": "AI導入評估",
                        "questions": [
                            {
                                "question_text": "在評估企業是否適合導入AI系統時，下列哪項是最優先考慮的關鍵因素？",
                                "options": {
                                    "A": "市場競爭趨勢",
                                    "B": "明確的業務目標",
                                    "C": "領導層個人態度",
                                    "D": "企業社群影響力"
                                },
                                "correct_answer": "B",
                                "solution": "(B) 正確。在評估企業是否適合導入AI系統時，清晰定義的業務問題和目標是最優先考慮的關鍵因素。這是因為AI應該被視為解決特定業務問題的工具，而非僅僅因為跟隨趨勢或競爭對手而導入。企業必須首先明確AI將解決什麼具體問題以及期望達到什麼目標，這樣才能評估AI是否真正適合以及後續如何衡量其價值。\n\n(A) 競爭對手是否已經採用AI技術固然是一個參考因素，但不應是最優先考慮的關鍵因素，因為每個企業的業務環境、問題和目標各不相同。\n\n(C) 執行長對AI的個人興趣不足以作為評估企業是否適合導入AI的關鍵因素，因為技術導入應基於業務需求而非個人喜好。\n\n(D) 社交媒體影響力與企業是否適合導入AI沒有直接關聯，不應作為評估的關鍵因素。"
                            },
                            {
                                "question_text": "下列哪項不是評估企業是否準備好導入AI時需考慮的數據因素？",
                                "options": {
                                    "A": "數據質量完整性",
                                    "B": "數據存取便利性",
                                    "C": "企業成立年限",
                                    "D": "數據特徵相關性"
                                },
                                "correct_answer": "C",
                                "solution": "(C) 正確。企業歷史的悠久程度並不是評估其是否準備好導入AI的直接相關因素。公司的成立時間長短本身與其數據準備程度、技術能力或業務問題的適合性沒有必然聯繫。相反，數據質量和數據量是否足夠、數據是否容易獲取和整合以及數據是否涵蓋目標問題的相關特徵，這些都是評估企業是否準備好導入AI時需要考慮的關鍵數據因素。AI系統的有效性高度依賴於用於訓練和運行系統的數據的質量、可取得性及相關性。"
                            },
                            {
                                "question_text": "評估AI專案的投資回報率(ROI)時，下列哪項不是典型的成本考量因素？",
                                "options": {
                                    "A": "數據收集處理成本",
                                    "B": "系統開發部署成本",
                                    "C": "競爭對手市場份額",
                                    "D": "長期維運更新成本"
                                },
                                "correct_answer": "C",
                                "solution": "(C) 正確。在評估AI專案的投資回報率(ROI)時，「競爭對手的市場份額」不是典型的成本考量因素。競爭對手的市場份額是市場分析或競爭情報的一部分，可能會影響企業採用AI的決策或策略，但它本身不是計算AI專案投資回報率時的成本項目。相比之下，數據收集和準備的成本、AI系統開發和部署的成本、以及系統維護和更新的長期成本都是計算AI專案總成本時需要考慮的典型因素。這些成本與專案的實際實施和運營直接相關，對於準確計算ROI至關重要。"
                            },
                            {
                                "question_text": "在評估企業AI成熟度時，下列哪一階段的組織已經在全公司範圍內標準化了AI流程和實踐？",
                                "options": {
                                    "A": "初步探索階段",
                                    "B": "試驗執行階段",
                                    "C": "全面整合階段",
                                    "D": "策略轉型階段"
                                },
                                "correct_answer": "C",
                                "solution": "(C) 正確。根據知識文件關於企業AI成熟度模型的描述，整合階段(Integrated)的組織已經在全公司範圍內標準化了AI流程和實踐。在這個階段，組織已經建立了明確的AI治理結構，AI專案是根據組織範圍的策略來優先排序和實施，並且有標準化的數據管道和操作流程。\n\n(A) 初始階段的組織僅有非正式或個別的AI計劃，缺乏組織層面的支持。\n\n(B) 實驗階段的組織可能有一些AI試點項目，但尚未有標準化的流程。\n\n(D) 轉型階段是最高級別的成熟度，此時AI已經完全融入組織的DNA和商業模式中，成為組織競爭優勢的核心驅動力。"
                            },
                            {
                                "question_text": "對於評估是否適合採用AI解決方案，下列哪種業務問題特徵最適合AI應用？",
                                "options": {
                                    "A": "高度道德判斷問題",
                                    "B": "模式明確重複任務",
                                    "C": "全新創新性挑戰",
                                    "D": "高度人工審核流程"
                                },
                                "correct_answer": "B",
                                "solution": "(B) 正確。具有清晰模式且大量重複的任務最適合AI應用。AI系統特別擅長於從大量數據中識別模式並自動執行重複性任務，可以提高效率並減少錯誤。例如，文件分類、基本客戶服務請求處理、標準化分析等任務都是AI應用的理想候選。\n\n(A) 需要高度道德判斷的決策通常不適合完全自動化，因為道德判斷涉及複雜的社會和文化背景，AI難以正確處理這些微妙的考量。\n\n(C) 需要創造性地解決前所未見的新問題對AI來說也是挑戰，因為現有的AI系統主要基於過去數據學習模式，對於完全新穎的情境處理能力有限。\n\n(D) 必須由人類進行最終審批的流程可以由AI輔助但不適合完全自動化，這類流程更適合人機協作的模式而非純AI解決方案。"
                            }
                        ]
                    },
                    "L21202": {
                        "title": "AI導入規劃",
                        "questions": [
                            {
                                "question_text": "企業在規劃AI系統導入時，下列哪一項不是典型的第一階段活動？",
                                "options": {
                                    "A": "業務需求界定",
                                    "B": "數據準備評估",
                                    "C": "系統全面部署",
                                    "D": "成功指標訂定"
                                },
                                "correct_answer": "C",
                                "solution": "(C) 正確。進行大規模系統部署不是AI系統導入規劃的第一階段活動，而是在完成前期評估、小規模試驗並驗證可行性之後的後期階段。在AI導入的初始階段，企業應先識別和定義業務問題，明確AI將解決的具體挑戰；評估數據準備程度，包括數據的可用性、質量和相關性；以及設定明確的成功指標，以便後續評估AI系統的效果。大規模部署前需要進行小規模概念驗證或試點項目，確保技術可行且能夠實現預期目標，這通常不會在導入規劃的第一階段進行。"
                            },
                            {
                                "question_text": "在安排AI專案優先順序時，下列哪個因素權重通常最低？",
                                "options": {
                                    "A": "業務問題重要性",
                                    "B": "技術實施可行性",
                                    "C": "投資回報預期值",
                                    "D": "競爭採用狀況"
                                },
                                "correct_answer": "D",
                                "solution": "(D) 正確。在安排AI專案優先順序時，「競爭對手是否已採用類似技術」通常權重最低。雖然了解競爭對手的動向對市場定位有一定參考價值，但不應成為決定AI專案優先級的主要因素。相比之下，專案解決業務問題的重要性（關聯到組織核心目標的程度），實施的技術可行性（包括所需技術資源和能力的可獲得性）以及專案的投資回報預期（成本與預期收益的對比）都是安排AI專案優先順序時更為關鍵的因素。"
                            },
                            {
                                "question_text": "對於一家中型企業首次導入AI，下列哪種方法最可能是明智的起步策略？",
                                "options": {
                                    "A": "全公司複雜系統導入",
                                    "B": "小型明確試點專案",
                                    "C": "大規模數據團隊建立",
                                    "D": "高額先進設備投資"
                                },
                                "correct_answer": "B",
                                "solution": "(B) 正確。對於首次導入AI的中型企業，從一個定義明確的小型試點專案開始是最明智的起步策略。這種方法可以降低風險，允許企業在較小的範圍內學習和適應AI技術，識別潛在的挑戰，並在擴展之前證明價值。\n\n(A) 立即在全公司範圍內部署複雜的機器學習系統風險過高，可能導致資源浪費和項目失敗。\n\n(C) 聘請50名數據科學家組建大型AI團隊對於初次導入AI的中型企業來說成本過高且不必要。\n\n(D) 投資數百萬美元建立最先進的AI基礎設施在驗證商業價值之前也是不合理的風險投資。逐步擴展的方法更有利於組織學習和適應，同時降低風險。"
                            },
                            {
                                "question_text": "制定AI導入路線圖時，下列哪一項應該最先考慮？",
                                "options": {
                                    "A": "詳細預算規劃",
                                    "B": "業務目標定義",
                                    "C": "技術架構選擇",
                                    "D": "團隊角色分工"
                                },
                                "correct_answer": "B",
                                "solution": "(B) 正確。在制定AI導入路線圖時，明確的業務目標和預期成果應該最先考慮。這是因為AI導入的根本目的是解決特定業務問題並實現商業價值，明確的業務目標將指導後續的所有決策，包括技術選擇、資源分配和實施策略。沒有明確的業務目標，AI專案容易偏離方向或無法證明其價值。預算配置細節、技術架構的具體實現和團隊成員的具體分工都是在確定了業務目標和基本策略之後才能具體規劃的因素。"
                            },
                            {
                                "question_text": "在AI導入規劃中，「人機協同」方法的主要優勢是什麼？",
                                "options": {
                                    "A": "完全避免人工介入",
                                    "B": "降低整體導入成本",
                                    "C": "結合人工智能互補",
                                    "D": "減少數據需求量"
                                },
                                "correct_answer": "C",
                                "solution": "(C) 正確。在AI導入規劃中，「人機協同」(Human-AI collaboration)方法的主要優勢是結合AI的效率和人類的判斷力。這種方法讓AI系統處理計算密集型和重複性任務，同時人類專家提供創造力、情感智能、道德判斷和處理邊緣案例的能力。\n\n(A) 「人機協同」並非旨在完全消除對人工的依賴，相反，它強調人類和AI各自優勢的互補性。\n\n(B) 人機協同不一定比純自動化解決方案便宜，其價值在於提高決策質量和處理複雜情境的能力，而非成本節約。\n\n(D) 人機協同也不會降低數據需求，AI部分仍需要足夠的高質量數據才能有效運作。"
                            }
                        ]
                    },
                    "L21203": {
                        "title": "AI風險管理",
                        "questions": [
                            {
                                "question_text": "在AI系統部署中，「算法偏見」(Algorithmic Bias)主要源於以下哪一項？",
                                "options": {
                                    "A": "硬件故障",
                                    "B": "訓練數據中的歷史或社會不平等",
                                    "C": "使用開源軟件",
                                    "D": "雲服務提供商的政策"
                                },
                                "correct_answer": "B",
                                "solution": "(B) 正確。算法偏見主要源於訓練數據中存在的歷史或社會不平等。當AI系統使用包含既有偏見或不平等的數據進行訓練時，它可能會「學習」並放大這些偏見，導致對特定群體的不公平結果。例如，如果歷史招聘數據中存在性別歧視，基於這些數據訓練的AI招聘系統可能會繼續偏向特定性別的候選人。\n\n(A) 硬件故障不會直接導致算法偏見，而是可能導致系統性能問題。\n\n(C) 使用開源軟件本身不會導致偏見，關鍵在於軟件使用的數據和設計的公平性。\n\n(D) 雲服務提供商的政策可能會影響系統的可用性或合規性，但不是算法偏見的直接來源。"
                            },
                            {
                                "question_text": "下列哪項不是減輕AI系統中算法偏見的有效策略？",
                                "options": {
                                    "A": "使用多樣化且代表性的訓練數據",
                                    "B": "假設所有AI決策都是完全客觀的",
                                    "C": "定期審計AI系統的決策結果",
                                    "D": "使用公平性指標監控模型表現"
                                },
                                "correct_answer": "B",
                                "solution": "(B) 正確。假設所有AI決策都是完全客觀的不是減輕算法偏見的有效策略，反而是一種危險的誤解。AI系統是基於人類創建的數據和算法構建的，因此可能繼承並放大人類社會中存在的偏見。正確的方法是承認偏見可能存在，並積極採取措施來識別和減輕它。\n\n(A) 使用多樣化且具有代表性的訓練數據可以幫助確保AI系統對不同人群都公平公正。\n\n(C) 定期審計AI系統的決策結果有助於發現潛在偏見模式。\n\n(D) 使用公平性指標監控模型表現可以量化評估AI系統對不同群體的影響是否公平。"
                            },
                            {
                                "question_text": "關於AI系統的隱私風險管理，以下哪種做法是不正確的？",
                                "options": {
                                    "A": "實施數據最小化原則，只收集必要數據",
                                    "B": "在收集數據前獲得明確知情同意",
                                    "C": "實施強大的數據安全措施",
                                    "D": "一旦獲得用戶同意，就可永久存儲所有數據"
                                },
                                "correct_answer": "D",
                                "solution": "(D) 正確。「一旦獲得用戶同意，就可永久存儲所有數據」是一種不正確的隱私風險管理做法。即使獲得了初始同意，數據保留也應遵循數據最小化原則和有限期限。組織應定期審查所存儲的數據，並在不再需要時安全刪除，而非無限期保留。\n\n(A) 實施數據最小化原則（只收集實現特定目的所必需的數據）是正確的隱私風險管理做法。\n\n(B) 在收集數據前獲得明確知情同意（確保用戶了解其數據如何被使用）是正確的隱私風險管理做法。\n\n(C) 實施強大的數據安全措施（如加密、訪問控制等）是正確的隱私風險管理做法。"
                            },
                            {
                                "question_text": "在企業部署AI系統時，下列哪種風險管理策略最能確保系統決策的可解釋性？",
                                "options": {
                                    "A": "僅使用最先進的深度學習模型",
                                    "B": "使用完全「黑盒」模型以保護商業機密",
                                    "C": "建立解釋AI決策的機制和工具",
                                    "D": "避免向最終用戶解釋系統如何工作"
                                },
                                "correct_answer": "C",
                                "solution": "(C) 正確。建立解釋AI決策的機制和工具是最能確保系統決策可解釋性的風險管理策略。這可能包括使用固有可解釋的模型、開發後解釋工具、提供決策因素的可視化或生成自然語言解釋等。可解釋性對於建立用戶信任、滿足監管要求和識別潛在偏見至關重要。\n\n(A) 僅使用最先進的深度學習模型可能會降低可解釋性，因為這些模型往往更複雜、更難解釋。\n\n(B) 使用完全「黑盒」模型以保護商業機密直接違背可解釋性的目標。\n\n(D) 避免向最終用戶解釋系統如何工作同樣不利於建立信任和透明度，不應作為管理策略。"
                            },
                            {
                                "question_text": "關於AI系統的責任分配(Accountability)，下列哪項是錯誤的？",
                                "options": {
                                    "A": "應明確定義AI系統相關決策和行動的責任人",
                                    "B": "一旦系統投入使用，結果由AI自己負責",
                                    "C": "應建立監督機制確保AI系統按預期運行",
                                    "D": "發生問題時應有明確的上報和處理流程"
                                },
                                "correct_answer": "B",
                                "solution": "(B) 正確。「一旦系統投入使用，結果由AI自己負責」是一種錯誤的責任分配觀念。AI系統本身不具備法律人格或道德責任能力，因此不能自行承擔責任。責任始終應該落在人類身上，包括系統的開發者、部署者和管理者。\n\n(A) 明確定義AI系統相關決策和行動的責任人是正確的責任分配做法。\n\n(C) 建立監督機制確保AI系統按預期運行是正確的責任分配做法。\n\n(D) 發生問題時有明確的上報和處理流程是正確的責任分配做法。這些措施共同確保了AI系統的責任框架，使人類持續對AI系統的行為和結果保持控制和問責。"
                            }
                        ]
                    }
                }
            },
            "L213": {
                "title": "AI 技術應用與系統部署",
                "sub_sections": {
                    "L21301": {
                        "title": "數據準備與模型選擇",
                        "questions": [
                            {
                                "question_text": "在AI項目中，下列哪一項不是數據預處理階段的典型任務？",
                                "options": {
                                    "A": "數據清洗處理",
                                    "B": "特徵工程優化",
                                    "C": "業務需求定義",
                                    "D": "數據標準化"
                                },
                                "correct_answer": "C",
                                "solution": "(C) 正確。業務目標定義不是數據預處理階段的典型任務，而是AI項目生命週期中更早的規劃階段的任務。業務目標應該在收集和處理數據之前明確，因為它們將指導整個項目的方向，包括決定需要什麼類型的數據。相比之下，數據清洗（處理缺失值、異常值和不一致性）、特徵工程（創建、轉換或選擇有助於模型性能的特徵）和數據標準化（將不同範圍的特徵調整到相似尺度）都是數據預處理階段的典型任務，這些任務直接處理和準備數據使其適合建模。"
                            },
                            {
                                "question_text": "在選擇AI模型時，「模型可解釋性需求」最可能在哪種情境下成為首要考慮因素？",
                                "options": {
                                    "A": "遊戲角色動畫開發",
                                    "B": "社群內容點擊預測",
                                    "C": "醫療診斷決策輔助",
                                    "D": "音樂推薦系統設計"
                                },
                                "correct_answer": "C",
                                "solution": "(C) 正確。在醫療診斷輔助決策系統中，模型可解釋性需求最可能成為首要考慮因素。這是因為醫療決策直接影響患者健康和生命，醫生需要理解AI系統建議背後的原因才能做出負責任的臨床判斷，患者有權知道影響其治療的因素，且醫療領域通常有嚴格的監管要求，要求治療決策是可解釋和可驗證的。\n\n(A) 為遊戲開發角色動畫主要關注視覺效果而非理解決策過程。\n\n(B) 預測社交媒體內容點擊率和音樂串流服務的推薦系統雖然也會受益於可解釋性，但通常優先考慮準確性和性能，且錯誤的後果相對較小。\n\n(D) 音樂串流服務的推薦系統可能優先考慮準確性和個性化，錯誤推薦的後果相對輕微。"
                            },
                            {
                                "question_text": "在建立機器學習模型時，為什麼將數據分成訓練集、驗證集和測試集很重要？",
                                "options": {
                                    "A": "增加處理計算複雜度",
                                    "B": "防止數據外洩問題",
                                    "C": "評估模型泛化能力",
                                    "D": "減少訓練數據需求"
                                },
                                "correct_answer": "C",
                                "solution": "(C) 正確。將數據分成訓練集、驗證集和測試集的主要目的是評估模型對新數據的泛化能力並防止過擬合。訓練集用於模型學習，驗證集用於調整超參數和選擇模型，而測試集用於最終評估模型在未見過的數據上的表現。這種分割確保了我們能夠可靠地評估模型在實際應用中的預期表現，而不僅僅是它對已知數據的擬合能力。這種數據分割並不會增加計算複雜度，實際上可能減少計算需求，因為某些步驟只在較小的數據子集上執行。這種做法與防止數據洩露無關，而是關於正確評估模型性能。這也不會減少訓練所需的總數據量，事實上可能需要更多的初始數據以確保每個集合都有足夠的樣本。\n\n(A) 這種數據分割並不會增加計算複雜度，實際上可能減少計算需求，因為某些步驟只在較小的數據子集上執行。\n\n(B) 這種做法與防止數據洩露無關，而是關於正確評估模型性能。\n\n(D) 這也不會減少訓練所需的總數據量，事實上可能需要更多的初始數據以確保每個集合都有足夠的樣本。"
                            },
                            {
                                "question_text": "在AI專案中，何時使用預訓練模型(pre-trained models)而非從頭訓練是最合適的？",
                                "options": {
                                    "A": "擁有大量專業數據",
                                    "B": "計算資源非常充足",
                                    "C": "獨特任務無類似模型",
                                    "D": "資源有限任務標準"
                                },
                                "correct_answer": "D",
                                "solution": "(D) 正確。當資源有限且任務相對標準化時，使用預訓練模型而非從頭訓練是最合適的。預訓練模型已在大型數據集上訓練過，能夠提供良好的起點，可以節省大量計算資源和時間，特別適合於計算資源有限或訓練數據不足的情況。\n\n(A) 當有大量領域特定的標記數據時，可能更適合從頭訓練模型或至少對預訓練模型進行更深入的微調，以充分利用這些數據。\n\n(B) 當計算資源充足且不受時間限制時，從頭訓練可能會產生更針對特定任務優化的結果。\n\n(C) 當處理非常獨特且專業的任務，沒有現成模型時，通常需要自定義模型架構和從頭訓練，因為預訓練模型可能不適用。"
                            },
                            {
                                "question_text": "在機器學習中，「過擬合」(overfitting)的最佳解釋是什麼？",
                                "options": {
                                    "A": "模型過於簡單",
                                    "B": "模型過於複雜",
                                    "C": "訓練數據太少",
                                    "D": "訓練時間過長"
                                },
                                "correct_answer": "B",
                                "solution": "(B) 正確。「過擬合」(overfitting)的最佳解釋是模型過於複雜，學習了訓練數據中的噪聲和隨機波動。過擬合發生在模型在訓練數據上表現很好，但在新數據上表現不佳的情況。這是因為模型不僅學習了數據中的真實模式，還學習了訓練集特有的噪聲和隨機波動，導致泛化能力差。\n\n(A) 模型太簡單，無法捕捉數據中的模式是「欠擬合」(underfitting)的描述，是一個不同的問題。\n\n(C) 訓練數據太少可能會增加過擬合的風險，但本身不是過擬合的定義。\n\n(D) 模型訓練時間過長可能導致過擬合，但不是過擬合本身的定義。"
                            }
                        ]
                    },
                    "L21302": {
                        "title": "AI技術系統集成與部署",
                        "questions": [
                            {
                                "question_text": "在AI系統部署中，下列哪種方式不是典型的部署模式？",
                                "options": {
                                    "A": "雲端部署",
                                    "B": "邊緣部署",
                                    "C": "混合部署",
                                    "D": "記憶體持久化部署"
                                },
                                "correct_answer": "D",
                                "solution": "(D) 正確。「記憶體持久化部署」不是AI系統的典型部署模式。AI系統的典型部署模式包括雲端部署（將AI系統部署在雲服務提供商的基礎設施上）、邊緣部署（將AI系統部署在靠近數據生成和使用點的設備上）以及混合部署（結合雲端和邊緣部署的優勢）。「記憶體持久化」是一個與數據存儲相關的概念，指將數據保持在記憶體中以提高訪問速度，但不是AI系統的整體部署模式。"
                            },
                            {
                                "question_text": "對於需要處理敏感醫療數據且要求低延遲的AI醫療診斷輔助系統，以下哪種部署方式最合適？",
                                "options": {
                                    "A": "完全雲端部署",
                                    "B": "邊緣部署",
                                    "C": "僅移動設備部署",
                                    "D": "公共區塊鏈部署"
                                },
                                "correct_answer": "B",
                                "solution": "(B) 正確。對於需要處理敏感醫療數據且要求低延遲的AI醫療診斷輔助系統，邊緣部署最為合適。邊緣部署將AI處理能力放置在靠近數據生成和使用的位置（如醫院的本地伺服器），這帶來幾個關鍵優勢：首先，敏感的醫療數據可以保持在本地處理，不必傳輸到外部雲服務，提高數據安全性和隱私保護；其次，由於數據不需要傳輸到遙遠的數據中心，可以顯著降低延遲，實現近實時的診斷響應；最後，即使網絡連接不穩定，系統也能繼續運行，提高可靠性。完全雲端部署會引入數據傳輸延遲，並增加敏感醫療數據外傳的風險。僅移動設備部署通常計算能力有限，可能無法處理複雜的醫療AI模型。公共區塊鏈部署不適合處理敏感醫療數據，且通常處理速度較慢，不適合低延遲需求。\n\n(A) 完全雲端部署會引入數據傳輸延遲，並增加敏感醫療數據外傳的風險。\n\n(C) 僅移動設備部署通常計算能力有限，可能無法處理複雜的醫療AI模型。\n\n(D) 公共區塊鏈部署不適合處理敏感醫療數據，且通常處理速度較慢，不適合低延遲需求。"
                            },
                            {
                                "question_text": "在AI系統開發週期中，「CI/CD」指的是什麼？",
                                "options": {
                                    "A": "計算智能/計算診斷 (Computational Intelligence/Computational Diagnostics)",
                                    "B": "客戶界面/客戶數據 (Customer Interface/Customer Data)",
                                    "C": "持續集成/持續部署 (Continuous Integration/Continuous Deployment)",
                                    "D": "認知互動/創意設計 (Cognitive Interaction/Creative Design)"
                                },
                                "correct_answer": "C",
                                "solution": "(C) 正確。在AI系統開發週期中，「CI/CD」指的是持續集成/持續部署(Continuous Integration/Continuous Deployment)。這是一種實踐方法，它使開發團隊能夠頻繁地將代碼變更合併到共享存儲庫中（持續集成），並自動部署新版本到生產環境（持續部署）。在AI系統開發中，CI/CD特別重要，因為它可以自動化模型訓練、評估和部署的過程，確保新模型的可靠發布，並能夠快速應對性能下降或數據漂移等問題。\n\n(A) 「CI/CD」不是計算智能/計算診斷的縮寫。\n\n(B) 「CI/CD」不是客戶界面/客戶數據的縮寫。\n\n(D) 「CI/CD」不是認知互動/創意設計的縮寫。"
                            },
                            {
                                "question_text": "在部署AI系統時，實施「金絲雀部署」(Canary Deployment)的主要目的是什麼？",
                                "options": {
                                    "A": "減少部署成本",
                                    "B": "通過漸進式發布減少風險",
                                    "C": "增加系統的最大用戶容量",
                                    "D": "提升系統的計算性能"
                                },
                                "correct_answer": "B",
                                "solution": "(B) 正確。實施「金絲雀部署」(Canary Deployment)的主要目的是通過漸進式發布減少風險。這種部署方法首先將新版本的應用或模型發布給一小部分用戶或流量，然後監控其性能和影響，如果一切正常，再逐步增加覆蓋範圍，直到完全部署。這種方法允許團隊在潛在問題影響大量用戶之前及早發現並解決問題，降低了大規模部署失敗的風險。金絲雀部署的名稱源於礦工過去用金絲雀探測礦井中的有害氣體，類似地，初始的小規模部署可以作為「金絲雀」來檢測問題。\n\n(A) 金絲雀部署不以減少部署成本為主要目的，反而可能增加部署的複雜性和短期成本。\n\n(C) 它也不直接關注增加系統的最大用戶容量，雖然它可以幫助確保新版本的性能在擴展前符合預期。\n\n(D) 它不直接提升系統的計算性能，而是專注於安全地驗證新版本的表現。"
                            },
                            {
                                "question_text": "在AI系統與企業現有系統集成時，API(應用程序接口)的主要作用是什麼？",
                                "options": {
                                    "A": "僅提供數據存儲功能",
                                    "B": "取代所有現有的企業軟件",
                                    "C": "提供標準化的通信接口，連接不同系統",
                                    "D": "降低系統的安全性以提高效率"
                                },
                                "correct_answer": "C",
                                "solution": "(C) 正確。在AI系統與企業現有系統集成時，API(應用程序接口)的主要作用是提供標準化的通信接口，連接不同系統。API定義了不同系統之間交互的規則和方法，使得AI系統能夠與企業的現有系統（如ERP、CRM、數據庫等）無縫集成和通信，而不需要深入了解各自的內部工作原理。這種標準化接口大大簡化了系統集成的複雜性，使不同團隊開發的系統能夠協同工作。\n\n(A) API不僅限於提供數據存儲功能，而是提供更廣泛的功能接口。\n\n(B) API的目的是促進系統間的集成，而非取代現有企業軟件。\n\n(D) 設計良好的API應該增強而非降低系統安全性，通過授權機制和數據驗證來保護系統資源。"
                            }
                        ]
                    }
                }
            }
        }
    }
}
